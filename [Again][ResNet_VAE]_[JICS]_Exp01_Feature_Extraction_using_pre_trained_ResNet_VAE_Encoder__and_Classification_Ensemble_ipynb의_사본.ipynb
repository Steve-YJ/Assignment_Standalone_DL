{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Again][ResNet-VAE] [JICS] Exp01. Feature_Extraction_using pre-trained ResNet-VAE Encoder _and_Classification_Ensemble .ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOfNHFwhyv6P0xjx0Jek4Dk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb4232e43a274592993f23bca5380264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_361e6729ee4b4ad89a8dafb73d3df91f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c7962336eb6c48db98410c7517a06cc0",
              "IPY_MODEL_2747f268d4e142d1b307c1740f1417c1"
            ]
          }
        },
        "361e6729ee4b4ad89a8dafb73d3df91f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7962336eb6c48db98410c7517a06cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_01c15c3b84ce42078789c8b49ca7007e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7bcefa1409b94be2bfd46655312af61b"
          }
        },
        "2747f268d4e142d1b307c1740f1417c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3b7be1291c684519b3bedd84c9db12f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:13&lt;00:00, 17.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69df84386dd14314b8498227f65ef205"
          }
        },
        "01c15c3b84ce42078789c8b49ca7007e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7bcefa1409b94be2bfd46655312af61b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b7be1291c684519b3bedd84c9db12f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69df84386dd14314b8498227f65ef205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Steve-YJ/Assignment_Standalone_DL/blob/master/%5BAgain%5D%5BResNet_VAE%5D_%5BJICS%5D_Exp01_Feature_Extraction_using_pre_trained_ResNet_VAE_Encoder__and_Classification_Ensemble_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EskqGIauJhlT"
      },
      "source": [
        "# README.MD\n",
        "## Preparing JICS\n",
        "* 🏅 Try as many as possible\n",
        "* For Variant Malware Classification\n",
        "    * Feature Extraction: Use pre-trained ResNet-VAE's Encoder Network\n",
        "    * 📌 Malware Family Classification: Emsemble Model\n",
        "    * 📌📌 Evaluation\n",
        "        * ✅ Accuracy\n",
        "        * ✅ precision, recall, F-1 Score etc...\n",
        "        * 📌📌 Make Plot!!\n",
        "* Experiment Details\n",
        "    * 1. Load pre-trained ResNet-VAE's Encoder Network\n",
        "        * Do-it: Feature Extraction using pre-trained ResNet-VAE's Encoder\n",
        "    * 2. Data Preparation\n",
        "        * Do-it: \n",
        "            * Feature Extraction\n",
        "            * Data Preparation\n",
        "            * Train_Test_Split\n",
        "    * 3. Model Definition\n",
        "        * Do-it: make Ensemble Classifier\n",
        "    * 4. Evaluation\n",
        "        * Do-it: Model Evaluation\n",
        "            * Accuracy, precision, recall, F-1 Score, ROC ...\n",
        "            \n",
        "✅ Check Point<br>\n",
        "\"틈틈히 Refactoring 합시다...!!\"\n",
        ">  1. Load ResNet-VAE's 92th Model&Optim Parameters\n",
        ">  2. Hyperparameter Optimization\n",
        ">  3. Make Ensemble Classifier\n",
        ">  4. 📌📌 Exp Report & Save Results\n",
        "\n",
        "<code>from--- 20.09.28.mon am 00:30 ~ </code><br>\n",
        "<code>Cont...--- 20.09.29.tue pm 11:30 ~ </code><br>\n",
        "<code>Cont...--- 20.09.30.wed am 08:30 ~ </code>\n",
        "\n",
        "\n",
        "<br>\n",
        "✅ Check Point<br>\n",
        "\n",
        "* Change Plan\n",
        "   * Trying to Apply Hybrid Method with ResNet-VAE Feature Extractor -20.09.29.Tue-\n",
        "    * ✅ 1. ResNet-VAE & Ensemble Classifier\n",
        "    * 2. ResNet-VAE & MLP(Multi-Layer Perceptron)\n",
        "    * 3. ResNet-VAE & CNN Classifier\n",
        "\n",
        "> 🔖 Kaggle Kernel, git, tutorial 등을 참고해서 report 실험을 할 수 있다면 좋을 것 같습니다<br>\n",
        "> ✅ 좀 더 Fancy한 모델을 통해 Accuracy, Precision, Recall, F-1 Score 등 평가 지수 높이기...!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs44oSmkvaTh"
      },
      "source": [
        "---\n",
        " ✋ Hyperparameter Optimization(하이퍼 파라미터 최적화)는 조금 미뤄두자.<br></br>\n",
        "우선은 계획대로 실험을 진행해보자...! -20.09.28.mon-\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-w7cWmrKVOF"
      },
      "source": [
        "# Mount Drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AItuRBfmKXDQ",
        "outputId": "59200990-475b-4ef2-b8e0-5c54ef041c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7tQumIsMaGD"
      },
      "source": [
        "<code>Auto Reload</code>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTnSkTNRMeAb"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THlFL3wGMk1H",
        "outputId": "749b642e-cd48-4adf-fe56-a6a7e14a5a2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "%cd drive/My\\ Drive/Post_InfoSec_Exps/ResNet-VAE/ResNetVAE-master.zip (Unzipped Files)/ResNetVAE-master\n",
        "# ! ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Post_InfoSec_Exps/ResNet-VAE/ResNetVAE-master.zip (Unzipped Files)/ResNetVAE-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hESv2ea0MxBb"
      },
      "source": [
        "import os \n",
        "\n",
        "def check_mkdir(dir_name):\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.mkdir(dir_name)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_XBFFaLM0hr"
      },
      "source": [
        "check_mkdir('./ResNet-VAE_Exp2_3_1.ResNet-VAE_Encoder_Transfer_Learning')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUnFTAWtNFLM",
        "outputId": "490f2771-91c1-4a33-fd9a-0677f769c0ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "source": [
        "! ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'01.Tutorial-ResNet-VAE.ipynb의 사본'\n",
            " 01.Tutorial-ResNet-VAE-Recon.ipynb\n",
            " 02.Tutorial-ResNet-VAE-Tunning.ipynb\n",
            " 03.Tutorial-ResNet-VAE-Tunning.ipynb\n",
            "'03.Tutorial-ResNet-VAE-Tunning.ipynb의 사본'\n",
            "'04.Post-01.Tutorial-ResNet-VAE.ipynb사본의 사본'\n",
            "'05.Post-01.Tutorial-ResNet-VAE_Train_Again.ipynb의 사본'\n",
            " 19train_val_plot.png\n",
            " 39train_val_plot.png\n",
            " 59train_val_plot.png\n",
            " Again_ResNet-VAE_Exp01\n",
            "'[Again][ResNet-VAE] Exp2_3_1. Transfer Learning Using ResNet-VAE'\\''Encoer.ipynb'\n",
            "'[Again][ResNet-VAE] Exp2_3_1. Transfer Learning Using ResNet-VAE'\\''Encoer.ipynb의 사본'\n",
            "'[Again][ResNet-VAE] [JICS] Exp01. Feature_Extraction_using pre-trained ResNet-VAE Encoder _and_Classification_Ensemble .ipynb의 사본'\n",
            "'[Again] ResNet-VAE_plus_Classifier .ipynb'\n",
            "'[Again] ResNet-VAE_plus_Classifier .ipynb의 사본'\n",
            "'[Again] Re-Start_Training_ResNet-VAE .ipynb'\n",
            " fig\n",
            " generated_Malimg.png\n",
            " modules.py\n",
            " plot_latent.ipynb\n",
            "'[Post_Exp]04-2.ResNet-VAE_Train_Again.ipynb'\n",
            "'[Post_Exp]04-2.ResNet-VAE_Train_Again.ipynb의 사본'\n",
            "'[Post_Exp]04-3.ResNet-VAE_Train_Again.ipynb'\n",
            "'[Post_Exp]04-3.ResNet-VAE_Train_Again.ipynb의 사본'\n",
            "'[Post_Exp]05-2.ResNet-VAE_Reduce_lr.ipynb'\n",
            " __pycache__\n",
            " README.md\n",
            " reconstruction_Malimg.png\n",
            " ResNetVAE_cifar10.py\n",
            " ResNet-VAE_Exp2_3_1.ResNet-VAE_Encoder_Transfer_Learning\n",
            " ResNet-VAE_Exp2_3_1.ResNet-VAE_Encoder_Transfer_Learning90Epoch_z_vector.npy\n",
            " ResNetVAE_FACE.py\n",
            " ResNetVAE_MNIST.py\n",
            " ResNetVAE_reconstruction.ipynb\n",
            " results_Malimg_Exp4\n",
            " results_Malimg_Exp4_3\n",
            " results_ResNet-VAE_Exp01\n",
            " results_ResNet-VAE_Exp01-Classification_Test\n",
            " save_loss_graph_accuracy.png\n",
            " train_test_loss_plot.png\n",
            " train_val_plot.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtIskK91Nf6Y",
        "outputId": "4c3d0dd0-ee7d-4ac3-b281-391f501de45d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "save_path =  'ResNet-VAE_Exp2_3_1.ResNet-VAE_Encoder_Transfer_Learning'\n",
        "save_path  # 실험 결과 저장 경로 설정"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ResNet-VAE_Exp2_3_1.ResNet-VAE_Encoder_Transfer_Learning'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inkcYChOKXN-"
      },
      "source": [
        "# #01. Import Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR_haOiVRmi6"
      },
      "source": [
        "* pre-trained ResNet-VAE 모델을 정의하고 불러오기 위해 관련 라이브러리 import\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1_2kwSgJUV-"
      },
      "source": [
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# save single numpy array\n",
        "from tempfile import TemporaryFile\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import torch\n",
        "import torch.utils.data  # torch.utils.data\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# argparse\n",
        "import argparse\n",
        "import time\n",
        "\n",
        "import torchvision \n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "# load modules\n",
        "from torchvision import models\n",
        "from modules import *"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-nGWHHxKbuy"
      },
      "source": [
        "# #02. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui3A2unwKg-M"
      },
      "source": [
        "transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3), # make 3-channel Images\n",
        "    transforms.ToTensor()])  # Composes several transforms together.\n",
        "\n",
        "# make custom dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='../../../../InformationSecurity_Summer/malimg',\n",
        "                                            transform=transforms)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUW1zlMsKhR5",
        "outputId": "bf03b25e-bfee-40a5-8310-4dc2064a756e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "classes = trainset.classes\n",
        "classes"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Adialer.C',\n",
              " 'Agent.FYI',\n",
              " 'Allaple.A',\n",
              " 'Allaple.L',\n",
              " 'Alueron.gen!J',\n",
              " 'Autorun.K',\n",
              " 'C2LOP.P',\n",
              " 'C2LOP.gen!g',\n",
              " 'Dialplatform.B',\n",
              " 'Dontovo.A',\n",
              " 'Fakerean',\n",
              " 'Instantaccess',\n",
              " 'Lolyda.AA1',\n",
              " 'Lolyda.AA2',\n",
              " 'Lolyda.AA3',\n",
              " 'Lolyda.AT',\n",
              " 'Malex.gen!J',\n",
              " 'Obfuscator.AD',\n",
              " 'Rbot!gen',\n",
              " 'Skintrim.N',\n",
              " 'Swizzor.gen!E',\n",
              " 'Swizzor.gen!I',\n",
              " 'VB.AT',\n",
              " 'Wintrim.BX',\n",
              " 'Yuner.A']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsvvauzuOghr"
      },
      "source": [
        "* Make Custom Dataset\n",
        "    * Train_Val_Test split\n",
        "<br>\n",
        "\n",
        "❌ 향후 ResNet-VAE Encoder Feature Extraction & MLP 학습에서 사용가능한 데이터 셋이 완성되었다<br>\n",
        "* Train: 7471\n",
        "* Val: 933\n",
        "* Test: 935\n",
        "<br>\n",
        "\n",
        "ResNet-VAE & MLP를 위해서는 뒤에서 다시 데이터셋을 생성해 줘야 한다 -20.09.30.wed- am 8:30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU8D_bMTLC8f",
        "outputId": "2d7e9924-06b2-4138-aa95-87e91d4639fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "full_dataset = trainset\n",
        "\n",
        "# maek train, val, test: 8:1:1\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = int(0.1 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "print(train_size, val_size, test_size)\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size, test_size])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7471 933 935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqTkaOwgPVoo"
      },
      "source": [
        "pre-trained ResNet-VAE 모델의 모델 parameter를 가져오기 위해 해당 실험때와 같은 hyperparameter를 설정해준다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOyiSg2uPdBc",
        "outputId": "8cf0182d-de72-4f17-fdc6-d7f5dad6626b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import argparse\n",
        "\n",
        "# ====== Random Seed Initialization ====== #\n",
        "seed = 123\n",
        "np.random.seed(seed)  # Reseed a legacy MT19937 BitGenerator\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "args = parser.parse_args(\"\")\n",
        "\n",
        "# ===== Model ====== #\n",
        "args.CNN_fc_hidden1 = 1024\n",
        "args.CNN_fc_hidden2 = 1024\n",
        "args.CNN_embed_dim = 256  # latent dim extracted by 2D CNN\n",
        "args.res_size = 224       # ResNet Image size\n",
        "\n",
        "# ===== Regularization ===== #\n",
        "args.dropout_p = 0.2           # dropout probability\n",
        "\n",
        "# ===== training parameters ====== #\n",
        "args.epochs = 20\n",
        "args.learning_rate = 1e-3\n",
        "\n",
        "args.batch_size = 50\n",
        "args.log_interval = 10  # interval for displaying training info\n",
        "\n",
        "print(args)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(CNN_embed_dim=256, CNN_fc_hidden1=1024, CNN_fc_hidden2=1024, batch_size=50, dropout_p=0.2, epochs=20, learning_rate=0.001, log_interval=10, res_size=224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFOiLznDDC1-"
      },
      "source": [
        "* z_loader's batch_size: 9339 -> 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsCTMS6FPhF7"
      },
      "source": [
        "Feature Extraction을 위해 train, val, test외에 z_loader를 정의해준다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjNp_6bXOVgE"
      },
      "source": [
        "# make custom data_loader\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                         batch_size=args.batch_size,\n",
        "                         shuffle=True,\n",
        "                         pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=args.batch_size,\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True)\n",
        " \n",
        "test_loader = DataLoader(test_dataset,\n",
        "                        batch_size=args.batch_size,\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True)  # Instead, we recommend using automatic memory pinning (i.e., setting pin_memory=True)\n",
        "                                          #  which enables fast data transfer to CUDA-enabled GPUs\n",
        "\n",
        "# First, insert all test dataset\n",
        "# z_loader: for latent vector extraction\n",
        "z_loader = DataLoader(full_dataset,\n",
        "                        batch_size=32,  # 128 -> 64 -> 32\n",
        "                        shuffle=False,  # Shuffle -> False\n",
        "                        pin_memory=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJCH1X2PKhcb"
      },
      "source": [
        "# #03. ResNet-VAE Architecture\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DROZCF6RN9i"
      },
      "source": [
        "## Make ResNet-VAE Architecture\n",
        "* Referenced: https://github.com/hsinyilin19/ResNetVAE/blob/master/modules.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQH5lml_ruWV"
      },
      "source": [
        "실험 결과 저장 경로 설정 <code>save_model_path</code>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-Iz5mg0Pv1q",
        "outputId": "3d342fd5-321f-4361-b74b-4aa70b2ca3f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "save_model_path = save_path\n",
        "save_model_path"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ResNet-VAE_Exp2_3_1.ResNet-VAE_Encoder_Transfer_Learning'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVvnNa3QPv4O"
      },
      "source": [
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    # MSE = F.mse_loss(recon_x, x, reduction='sum')\n",
        "    MSE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return MSE + KLD"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB52iWLDPv6c"
      },
      "source": [
        "class ResNet_VAE(nn.Module):\n",
        "    def __init__(self, fc_hidden1=1024, fc_hidden2=768, drop_p=0.3, CNN_embed_dim=256):\n",
        "        super(ResNet_VAE, self).__init__()\n",
        "\n",
        "        self.fc_hidden1, self.fc_hidden2, self.CNN_embed_dim = fc_hidden1, fc_hidden2, CNN_embed_dim\n",
        "\n",
        "        # CNN architechtures\n",
        "        self.ch1, self.ch2, self.ch3, self.ch4 = 16, 32, 64, 128\n",
        "        self.k1, self.k2, self.k3, self.k4 = (5, 5), (3, 3), (3, 3), (3, 3)      # 2d kernal size\n",
        "        self.s1, self.s2, self.s3, self.s4 = (2, 2), (2, 2), (2, 2), (2, 2)      # 2d strides\n",
        "        self.pd1, self.pd2, self.pd3, self.pd4 = (0, 0), (0, 0), (0, 0), (0, 0)  # 2d padding\n",
        "\n",
        "        # ====== Encoder ====== #\n",
        "        # encoding components\n",
        "        resnet = models.resnet152(pretrained=True)\n",
        "        modules = list(resnet.children())[:-1]      # delete the last fc layer.\n",
        "                                                    # pre-trained ResNet Architecture에서 마지막 FC레이어를 제외한 Model\n",
        "        # ====== Notice ======= #\n",
        "        # 이 코드를 잘 고치면 MLP Layer의 개수를 변경해 가면서 실험할 수 있겠다\n",
        "        self.resnet = nn.Sequential(*modules)\n",
        "        self.fc1 = nn.Linear(resnet.fc.in_features, self.fc_hidden1)\n",
        "        self.bn1 = nn.BatchNorm1d(self.fc_hidden1, momentum=0.01)\n",
        "        self.fc2 = nn.Linear(self.fc_hidden1, self.fc_hidden2)\n",
        "        self.bn2 = nn.BatchNorm1d(self.fc_hidden2, momentum=0.01)\n",
        "\n",
        "        # Latent vectors mu and sigma\n",
        "        self.fc3_mu = nn.Linear(self.fc_hidden2, self.CNN_embed_dim)      # output = CNN embedding latent variables\n",
        "        self.fc3_logvar = nn.Linear(self.fc_hidden2, self.CNN_embed_dim)  # output = CNN embedding latent variables\n",
        "\n",
        "        # Sampling vector\n",
        "        self.fc4 = nn.Linear(self.CNN_embed_dim, self.fc_hidden2)\n",
        "        self.fc_bn4 = nn.BatchNorm1d(self.fc_hidden2)\n",
        "        self.fc5 = nn.Linear(self.fc_hidden2, 64 * 4 * 4)\n",
        "        self.fc_bn5 = nn.BatchNorm1d(64 * 4 * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # ====== Decoder ====== #\n",
        "        # Decoder\n",
        "        self.convTrans6 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=self.k4, stride=self.s4,\n",
        "                               padding=self.pd4),\n",
        "            nn.BatchNorm2d(32, momentum=0.01),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.convTrans7 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=32, out_channels=8, kernel_size=self.k3, stride=self.s3,\n",
        "                               padding=self.pd3),\n",
        "            nn.BatchNorm2d(8, momentum=0.01),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.convTrans8 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=8, out_channels=3, kernel_size=self.k2, stride=self.s2,\n",
        "                               padding=self.pd2),\n",
        "            nn.BatchNorm2d(3, momentum=0.01),\n",
        "            nn.Sigmoid()    # y = (y1, y2, y3) \\in [0 ,1]^3\n",
        "        )\n",
        "\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.resnet(x)  # ResNet\n",
        "        x = x.view(x.size(0), -1)  # flatten output of conv\n",
        "\n",
        "        # FC layers\n",
        "        x = self.bn1(self.fc1(x))\n",
        "        x = self.relu(x)\n",
        "        x = self.bn2(self.fc2(x))\n",
        "        x = self.relu(x)\n",
        "        # x = F.dropout(x, p=self.drop_p, training=self.training)\n",
        "        mu, logvar = self.fc3_mu(x), self.fc3_logvar(x)\n",
        "        return mu, logvar  # check: Encoder -> hid1-BN-hid2-BN ==> x\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = Variable(std.data.new(std.size()).normal_())\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "\n",
        "    def decode(self, z):\n",
        "        x = self.relu(self.fc_bn4(self.fc4(z)))\n",
        "        x = self.relu(self.fc_bn5(self.fc5(x))).view(-1, 64, 4, 4)\n",
        "        x = self.convTrans6(x)\n",
        "        x = self.convTrans7(x)\n",
        "        x = self.convTrans8(x)\n",
        "        x = F.interpolate(x, size=(224, 224), mode='bilinear')\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_reconst = self.decode(z)\n",
        "\n",
        "        return x_reconst, z, mu, logvar"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H_gY437OknT"
      },
      "source": [
        "📌 Custom DataLoader의 경우, 자동화를 위해 Train, Val, Test 함수 내에 만들어준다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j8T8ki7LKZY",
        "outputId": "e30d5512-0676-4453-e6a0-a9470778c42c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Detect devices\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(use_cuda)\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLay2SvtSakU"
      },
      "source": [
        "95 Epoch이 최선이지만... 데이터를 지워버렸기에 ㅠ 차선인 Epoch 90의 값을 불러온다...!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxNeuVHLBHjh"
      },
      "source": [
        "아래의 셀을 실행하면 ./results_ResNet-VAE_Exp01에 저장되어있는 pre-trained model의 parameter값을 불러올 수 있다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT2a0U5jgVls",
        "outputId": "69227509-e252-437b-c919-334c1b1360ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pre_saved_model_path = './results_ResNet-VAE_Exp01'\n",
        "os.path.join(pre_saved_model_path, 'model_epoch{}.pth'.format(90))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./results_ResNet-VAE_Exp01/model_epoch90.pth'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyU66GrgSYxD"
      },
      "source": [
        "* 90 Epoch의 모델, 옵티마이져 파라미터를 불러온다\n",
        "* 이 때 모델의 Encoer Network를 통해 Feature Extraction만 진행할 경우 <code>model.eval()</code>을 꼭 해준다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLgjTPeNQGA3",
        "outputId": "722c0df8-734a-431e-aa8d-924e9cdd433d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "cb4232e43a274592993f23bca5380264",
            "361e6729ee4b4ad89a8dafb73d3df91f",
            "c7962336eb6c48db98410c7517a06cc0",
            "2747f268d4e142d1b307c1740f1417c1",
            "01c15c3b84ce42078789c8b49ca7007e",
            "7bcefa1409b94be2bfd46655312af61b",
            "3b7be1291c684519b3bedd84c9db12f1",
            "69df84386dd14314b8498227f65ef205"
          ]
        }
      },
      "source": [
        "### If you want to use pre-trained model ####\n",
        "pre_saved_model_path = './results_ResNet-VAE_Exp01'\n",
        "epoch=90\n",
        "\n",
        "# Create model\n",
        "resnet_vae = ResNet_VAE(fc_hidden1=args.CNN_fc_hidden1, fc_hidden2=args.CNN_fc_hidden2, drop_p=args.dropout_p, CNN_embed_dim=args.CNN_embed_dim).to(device)\n",
        "### If you want to use pre-trained model ####\n",
        "resnet_vae.load_state_dict(torch.load(os.path.join(pre_saved_model_path, 'model_epoch{}.pth'.format(epoch))))\n",
        "resnet_vae.eval()  # 오늘 한 건했던 model.eval()\n",
        "\n",
        "model_params = list(resnet_vae.parameters())\n",
        "optimizer = torch.optim.Adam(model_params, lr=args.learning_rate)\n",
        "### If you want to use pre-trained model's optimizer ####\n",
        "optimizer.load_state_dict(torch.load(os.path.join(pre_saved_model_path, 'optimizer_epoch{}.pth'.format(epoch))))\n",
        "\n",
        "\n",
        "print('Number of {} parameters'.format(sum(p.numel() for p in resnet_vae.parameters() if p.requires_grad)))\n",
        "print(\"Using\", torch.cuda.device_count(), \"GPU!\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb4232e43a274592993f23bca5380264",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Number of 63158425 parameters\n",
            "Using 1 GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKlygswKapgc",
        "outputId": "cd5905ac-da10-4eee-f28c-4e9ca6cca627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet_vae"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet_VAE(\n",
              "  (resnet): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (6): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (7): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (6): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (7): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (8): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (9): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (10): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (11): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (12): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (13): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (14): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (15): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (16): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (17): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (18): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (19): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (20): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (21): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (22): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (23): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (24): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (25): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (26): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (27): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (28): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (29): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (30): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (31): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (32): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (33): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (34): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (35): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "  (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (fc3_mu): Linear(in_features=1024, out_features=256, bias=True)\n",
              "  (fc3_logvar): Linear(in_features=1024, out_features=256, bias=True)\n",
              "  (fc4): Linear(in_features=256, out_features=1024, bias=True)\n",
              "  (fc_bn4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc5): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  (fc_bn5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (convTrans6): Sequential(\n",
              "    (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (convTrans7): Sequential(\n",
              "    (0): ConvTranspose2d(32, 8, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (convTrans8): Sequential(\n",
              "    (0): ConvTranspose2d(8, 3, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "    (2): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIDuGdu6LC-Y"
      },
      "source": [
        "# #04. Train, Validation, Test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n18INOByRLHm"
      },
      "source": [
        "## Training Ensemble Classifier\n",
        "After train ResNet-VAE, Use EncoderNet as Feature Extractor<br>\n",
        "<br>\n",
        "* Extract Latent Vector\n",
        "* Improve Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgkcP9eUa8El"
      },
      "source": [
        "* pre-traned ResNet-VAE의 Encoder를 <code>Feature Extractor</code>로 활용하여 분류 문제를 풀어보도록 한다. <code>20.09.28.mon pm4:00</code>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGmBlAxJbKBm"
      },
      "source": [
        "* Referernce:\n",
        "* 추가실험 List\n",
        "    * Load VAE_State_Dict\n",
        "    * Extract Latent vector & make Training set(for DL/ML)\n",
        "    * => For all training data: (9339, 256)  / Latent dim\n",
        "    * => Add Labels: (9339, 257)  # 256 feature 1 label\n",
        "    * Make Pandas DataFrame\n",
        "    * Make pd.DataFrame()\n",
        "    * Save DataFrame() to csv\n",
        "    * Make Classifier\n",
        "* Classification\n",
        "    * ML: Voting Classifier\n",
        "    * DL: ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-hcJ4gFjkZ0"
      },
      "source": [
        "# ResNet-VAE & Ensemble "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sigZH93KbHzs"
      },
      "source": [
        "## Extract Latent Vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHJlFTvRJINl"
      },
      "source": [
        "* 적당한 알고리즘을 짜야겠구나...! -20.09.28.mon pm6:50-\n",
        "* 📌 아래의 코드는 Feature Extraction을 수행할 때만 실행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv7W7bP1Fzx3"
      },
      "source": [
        "✅ 데이터는 백업이 생명이다...!!!<br>\n",
        "latent_vector 저장후 백업을 하도록 하자...!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGob8kg4bfTX",
        "outputId": "6f0301ed-d87c-435f-a4a0-88b326239e26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i, (data, _) in enumerate(z_loader):  # load_whole data(9339)\n",
        "    data = data.to(device)\n",
        "    # recon_batch, mu, logvar, z = resnet_vae(data)\n",
        "    recon_batch, z, mu, logvar = resnet_vae(data)  # batch_size만큼 값 저장\n",
        "    \n",
        "    # save latent_vector\n",
        "    latent_vector = z.detach().cpu().clone().numpy()  # change tensor type data to cpu().numpy()\n",
        "                                                        # latent_vector_size: (num_of_data, 256)  # num_of_data, num_of_dim\n",
        "    # save label\n",
        "    label = _.detach().cpu().clone().numpy()\n",
        "    label =label.reshape(1, -1)\n",
        "    print(label.shape)\n",
        "\n",
        "    # concat_data\n",
        "    if i == 0:\n",
        "        latent_z = np.concatenate((latent_vector, label.T), axis=1)  # latent_z: (9339, 101): (num_data, latent_z + label) \n",
        "        print(latent_z.shape)  # (32, 257): batch_num, features + label\n",
        "    elif i > 0:\n",
        "        latent_z = np.concatenate((latent_z,  np.concatenate((latent_vector, label.T), axis=1)), axis=0)\n",
        "        print(latent_z.shape)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1, 32)\n",
            "(32, 257)\n",
            "(1, 32)\n",
            "(64, 257)\n",
            "(1, 32)\n",
            "(96, 257)\n",
            "(1, 32)\n",
            "(128, 257)\n",
            "(1, 32)\n",
            "(160, 257)\n",
            "(1, 32)\n",
            "(192, 257)\n",
            "(1, 32)\n",
            "(224, 257)\n",
            "(1, 32)\n",
            "(256, 257)\n",
            "(1, 32)\n",
            "(288, 257)\n",
            "(1, 32)\n",
            "(320, 257)\n",
            "(1, 32)\n",
            "(352, 257)\n",
            "(1, 32)\n",
            "(384, 257)\n",
            "(1, 32)\n",
            "(416, 257)\n",
            "(1, 32)\n",
            "(448, 257)\n",
            "(1, 32)\n",
            "(480, 257)\n",
            "(1, 32)\n",
            "(512, 257)\n",
            "(1, 32)\n",
            "(544, 257)\n",
            "(1, 32)\n",
            "(576, 257)\n",
            "(1, 32)\n",
            "(608, 257)\n",
            "(1, 32)\n",
            "(640, 257)\n",
            "(1, 32)\n",
            "(672, 257)\n",
            "(1, 32)\n",
            "(704, 257)\n",
            "(1, 32)\n",
            "(736, 257)\n",
            "(1, 32)\n",
            "(768, 257)\n",
            "(1, 32)\n",
            "(800, 257)\n",
            "(1, 32)\n",
            "(832, 257)\n",
            "(1, 32)\n",
            "(864, 257)\n",
            "(1, 32)\n",
            "(896, 257)\n",
            "(1, 32)\n",
            "(928, 257)\n",
            "(1, 32)\n",
            "(960, 257)\n",
            "(1, 32)\n",
            "(992, 257)\n",
            "(1, 32)\n",
            "(1024, 257)\n",
            "(1, 32)\n",
            "(1056, 257)\n",
            "(1, 32)\n",
            "(1088, 257)\n",
            "(1, 32)\n",
            "(1120, 257)\n",
            "(1, 32)\n",
            "(1152, 257)\n",
            "(1, 32)\n",
            "(1184, 257)\n",
            "(1, 32)\n",
            "(1216, 257)\n",
            "(1, 32)\n",
            "(1248, 257)\n",
            "(1, 32)\n",
            "(1280, 257)\n",
            "(1, 32)\n",
            "(1312, 257)\n",
            "(1, 32)\n",
            "(1344, 257)\n",
            "(1, 32)\n",
            "(1376, 257)\n",
            "(1, 32)\n",
            "(1408, 257)\n",
            "(1, 32)\n",
            "(1440, 257)\n",
            "(1, 32)\n",
            "(1472, 257)\n",
            "(1, 32)\n",
            "(1504, 257)\n",
            "(1, 32)\n",
            "(1536, 257)\n",
            "(1, 32)\n",
            "(1568, 257)\n",
            "(1, 32)\n",
            "(1600, 257)\n",
            "(1, 32)\n",
            "(1632, 257)\n",
            "(1, 32)\n",
            "(1664, 257)\n",
            "(1, 32)\n",
            "(1696, 257)\n",
            "(1, 32)\n",
            "(1728, 257)\n",
            "(1, 32)\n",
            "(1760, 257)\n",
            "(1, 32)\n",
            "(1792, 257)\n",
            "(1, 32)\n",
            "(1824, 257)\n",
            "(1, 32)\n",
            "(1856, 257)\n",
            "(1, 32)\n",
            "(1888, 257)\n",
            "(1, 32)\n",
            "(1920, 257)\n",
            "(1, 32)\n",
            "(1952, 257)\n",
            "(1, 32)\n",
            "(1984, 257)\n",
            "(1, 32)\n",
            "(2016, 257)\n",
            "(1, 32)\n",
            "(2048, 257)\n",
            "(1, 32)\n",
            "(2080, 257)\n",
            "(1, 32)\n",
            "(2112, 257)\n",
            "(1, 32)\n",
            "(2144, 257)\n",
            "(1, 32)\n",
            "(2176, 257)\n",
            "(1, 32)\n",
            "(2208, 257)\n",
            "(1, 32)\n",
            "(2240, 257)\n",
            "(1, 32)\n",
            "(2272, 257)\n",
            "(1, 32)\n",
            "(2304, 257)\n",
            "(1, 32)\n",
            "(2336, 257)\n",
            "(1, 32)\n",
            "(2368, 257)\n",
            "(1, 32)\n",
            "(2400, 257)\n",
            "(1, 32)\n",
            "(2432, 257)\n",
            "(1, 32)\n",
            "(2464, 257)\n",
            "(1, 32)\n",
            "(2496, 257)\n",
            "(1, 32)\n",
            "(2528, 257)\n",
            "(1, 32)\n",
            "(2560, 257)\n",
            "(1, 32)\n",
            "(2592, 257)\n",
            "(1, 32)\n",
            "(2624, 257)\n",
            "(1, 32)\n",
            "(2656, 257)\n",
            "(1, 32)\n",
            "(2688, 257)\n",
            "(1, 32)\n",
            "(2720, 257)\n",
            "(1, 32)\n",
            "(2752, 257)\n",
            "(1, 32)\n",
            "(2784, 257)\n",
            "(1, 32)\n",
            "(2816, 257)\n",
            "(1, 32)\n",
            "(2848, 257)\n",
            "(1, 32)\n",
            "(2880, 257)\n",
            "(1, 32)\n",
            "(2912, 257)\n",
            "(1, 32)\n",
            "(2944, 257)\n",
            "(1, 32)\n",
            "(2976, 257)\n",
            "(1, 32)\n",
            "(3008, 257)\n",
            "(1, 32)\n",
            "(3040, 257)\n",
            "(1, 32)\n",
            "(3072, 257)\n",
            "(1, 32)\n",
            "(3104, 257)\n",
            "(1, 32)\n",
            "(3136, 257)\n",
            "(1, 32)\n",
            "(3168, 257)\n",
            "(1, 32)\n",
            "(3200, 257)\n",
            "(1, 32)\n",
            "(3232, 257)\n",
            "(1, 32)\n",
            "(3264, 257)\n",
            "(1, 32)\n",
            "(3296, 257)\n",
            "(1, 32)\n",
            "(3328, 257)\n",
            "(1, 32)\n",
            "(3360, 257)\n",
            "(1, 32)\n",
            "(3392, 257)\n",
            "(1, 32)\n",
            "(3424, 257)\n",
            "(1, 32)\n",
            "(3456, 257)\n",
            "(1, 32)\n",
            "(3488, 257)\n",
            "(1, 32)\n",
            "(3520, 257)\n",
            "(1, 32)\n",
            "(3552, 257)\n",
            "(1, 32)\n",
            "(3584, 257)\n",
            "(1, 32)\n",
            "(3616, 257)\n",
            "(1, 32)\n",
            "(3648, 257)\n",
            "(1, 32)\n",
            "(3680, 257)\n",
            "(1, 32)\n",
            "(3712, 257)\n",
            "(1, 32)\n",
            "(3744, 257)\n",
            "(1, 32)\n",
            "(3776, 257)\n",
            "(1, 32)\n",
            "(3808, 257)\n",
            "(1, 32)\n",
            "(3840, 257)\n",
            "(1, 32)\n",
            "(3872, 257)\n",
            "(1, 32)\n",
            "(3904, 257)\n",
            "(1, 32)\n",
            "(3936, 257)\n",
            "(1, 32)\n",
            "(3968, 257)\n",
            "(1, 32)\n",
            "(4000, 257)\n",
            "(1, 32)\n",
            "(4032, 257)\n",
            "(1, 32)\n",
            "(4064, 257)\n",
            "(1, 32)\n",
            "(4096, 257)\n",
            "(1, 32)\n",
            "(4128, 257)\n",
            "(1, 32)\n",
            "(4160, 257)\n",
            "(1, 32)\n",
            "(4192, 257)\n",
            "(1, 32)\n",
            "(4224, 257)\n",
            "(1, 32)\n",
            "(4256, 257)\n",
            "(1, 32)\n",
            "(4288, 257)\n",
            "(1, 32)\n",
            "(4320, 257)\n",
            "(1, 32)\n",
            "(4352, 257)\n",
            "(1, 32)\n",
            "(4384, 257)\n",
            "(1, 32)\n",
            "(4416, 257)\n",
            "(1, 32)\n",
            "(4448, 257)\n",
            "(1, 32)\n",
            "(4480, 257)\n",
            "(1, 32)\n",
            "(4512, 257)\n",
            "(1, 32)\n",
            "(4544, 257)\n",
            "(1, 32)\n",
            "(4576, 257)\n",
            "(1, 32)\n",
            "(4608, 257)\n",
            "(1, 32)\n",
            "(4640, 257)\n",
            "(1, 32)\n",
            "(4672, 257)\n",
            "(1, 32)\n",
            "(4704, 257)\n",
            "(1, 32)\n",
            "(4736, 257)\n",
            "(1, 32)\n",
            "(4768, 257)\n",
            "(1, 32)\n",
            "(4800, 257)\n",
            "(1, 32)\n",
            "(4832, 257)\n",
            "(1, 32)\n",
            "(4864, 257)\n",
            "(1, 32)\n",
            "(4896, 257)\n",
            "(1, 32)\n",
            "(4928, 257)\n",
            "(1, 32)\n",
            "(4960, 257)\n",
            "(1, 32)\n",
            "(4992, 257)\n",
            "(1, 32)\n",
            "(5024, 257)\n",
            "(1, 32)\n",
            "(5056, 257)\n",
            "(1, 32)\n",
            "(5088, 257)\n",
            "(1, 32)\n",
            "(5120, 257)\n",
            "(1, 32)\n",
            "(5152, 257)\n",
            "(1, 32)\n",
            "(5184, 257)\n",
            "(1, 32)\n",
            "(5216, 257)\n",
            "(1, 32)\n",
            "(5248, 257)\n",
            "(1, 32)\n",
            "(5280, 257)\n",
            "(1, 32)\n",
            "(5312, 257)\n",
            "(1, 32)\n",
            "(5344, 257)\n",
            "(1, 32)\n",
            "(5376, 257)\n",
            "(1, 32)\n",
            "(5408, 257)\n",
            "(1, 32)\n",
            "(5440, 257)\n",
            "(1, 32)\n",
            "(5472, 257)\n",
            "(1, 32)\n",
            "(5504, 257)\n",
            "(1, 32)\n",
            "(5536, 257)\n",
            "(1, 32)\n",
            "(5568, 257)\n",
            "(1, 32)\n",
            "(5600, 257)\n",
            "(1, 32)\n",
            "(5632, 257)\n",
            "(1, 32)\n",
            "(5664, 257)\n",
            "(1, 32)\n",
            "(5696, 257)\n",
            "(1, 32)\n",
            "(5728, 257)\n",
            "(1, 32)\n",
            "(5760, 257)\n",
            "(1, 32)\n",
            "(5792, 257)\n",
            "(1, 32)\n",
            "(5824, 257)\n",
            "(1, 32)\n",
            "(5856, 257)\n",
            "(1, 32)\n",
            "(5888, 257)\n",
            "(1, 32)\n",
            "(5920, 257)\n",
            "(1, 32)\n",
            "(5952, 257)\n",
            "(1, 32)\n",
            "(5984, 257)\n",
            "(1, 32)\n",
            "(6016, 257)\n",
            "(1, 32)\n",
            "(6048, 257)\n",
            "(1, 32)\n",
            "(6080, 257)\n",
            "(1, 32)\n",
            "(6112, 257)\n",
            "(1, 32)\n",
            "(6144, 257)\n",
            "(1, 32)\n",
            "(6176, 257)\n",
            "(1, 32)\n",
            "(6208, 257)\n",
            "(1, 32)\n",
            "(6240, 257)\n",
            "(1, 32)\n",
            "(6272, 257)\n",
            "(1, 32)\n",
            "(6304, 257)\n",
            "(1, 32)\n",
            "(6336, 257)\n",
            "(1, 32)\n",
            "(6368, 257)\n",
            "(1, 32)\n",
            "(6400, 257)\n",
            "(1, 32)\n",
            "(6432, 257)\n",
            "(1, 32)\n",
            "(6464, 257)\n",
            "(1, 32)\n",
            "(6496, 257)\n",
            "(1, 32)\n",
            "(6528, 257)\n",
            "(1, 32)\n",
            "(6560, 257)\n",
            "(1, 32)\n",
            "(6592, 257)\n",
            "(1, 32)\n",
            "(6624, 257)\n",
            "(1, 32)\n",
            "(6656, 257)\n",
            "(1, 32)\n",
            "(6688, 257)\n",
            "(1, 32)\n",
            "(6720, 257)\n",
            "(1, 32)\n",
            "(6752, 257)\n",
            "(1, 32)\n",
            "(6784, 257)\n",
            "(1, 32)\n",
            "(6816, 257)\n",
            "(1, 32)\n",
            "(6848, 257)\n",
            "(1, 32)\n",
            "(6880, 257)\n",
            "(1, 32)\n",
            "(6912, 257)\n",
            "(1, 32)\n",
            "(6944, 257)\n",
            "(1, 32)\n",
            "(6976, 257)\n",
            "(1, 32)\n",
            "(7008, 257)\n",
            "(1, 32)\n",
            "(7040, 257)\n",
            "(1, 32)\n",
            "(7072, 257)\n",
            "(1, 32)\n",
            "(7104, 257)\n",
            "(1, 32)\n",
            "(7136, 257)\n",
            "(1, 32)\n",
            "(7168, 257)\n",
            "(1, 32)\n",
            "(7200, 257)\n",
            "(1, 32)\n",
            "(7232, 257)\n",
            "(1, 32)\n",
            "(7264, 257)\n",
            "(1, 32)\n",
            "(7296, 257)\n",
            "(1, 32)\n",
            "(7328, 257)\n",
            "(1, 32)\n",
            "(7360, 257)\n",
            "(1, 32)\n",
            "(7392, 257)\n",
            "(1, 32)\n",
            "(7424, 257)\n",
            "(1, 32)\n",
            "(7456, 257)\n",
            "(1, 32)\n",
            "(7488, 257)\n",
            "(1, 32)\n",
            "(7520, 257)\n",
            "(1, 32)\n",
            "(7552, 257)\n",
            "(1, 32)\n",
            "(7584, 257)\n",
            "(1, 32)\n",
            "(7616, 257)\n",
            "(1, 32)\n",
            "(7648, 257)\n",
            "(1, 32)\n",
            "(7680, 257)\n",
            "(1, 32)\n",
            "(7712, 257)\n",
            "(1, 32)\n",
            "(7744, 257)\n",
            "(1, 32)\n",
            "(7776, 257)\n",
            "(1, 32)\n",
            "(7808, 257)\n",
            "(1, 32)\n",
            "(7840, 257)\n",
            "(1, 32)\n",
            "(7872, 257)\n",
            "(1, 32)\n",
            "(7904, 257)\n",
            "(1, 32)\n",
            "(7936, 257)\n",
            "(1, 32)\n",
            "(7968, 257)\n",
            "(1, 32)\n",
            "(8000, 257)\n",
            "(1, 32)\n",
            "(8032, 257)\n",
            "(1, 32)\n",
            "(8064, 257)\n",
            "(1, 32)\n",
            "(8096, 257)\n",
            "(1, 32)\n",
            "(8128, 257)\n",
            "(1, 32)\n",
            "(8160, 257)\n",
            "(1, 32)\n",
            "(8192, 257)\n",
            "(1, 32)\n",
            "(8224, 257)\n",
            "(1, 32)\n",
            "(8256, 257)\n",
            "(1, 32)\n",
            "(8288, 257)\n",
            "(1, 32)\n",
            "(8320, 257)\n",
            "(1, 32)\n",
            "(8352, 257)\n",
            "(1, 32)\n",
            "(8384, 257)\n",
            "(1, 32)\n",
            "(8416, 257)\n",
            "(1, 32)\n",
            "(8448, 257)\n",
            "(1, 32)\n",
            "(8480, 257)\n",
            "(1, 32)\n",
            "(8512, 257)\n",
            "(1, 32)\n",
            "(8544, 257)\n",
            "(1, 32)\n",
            "(8576, 257)\n",
            "(1, 32)\n",
            "(8608, 257)\n",
            "(1, 32)\n",
            "(8640, 257)\n",
            "(1, 32)\n",
            "(8672, 257)\n",
            "(1, 32)\n",
            "(8704, 257)\n",
            "(1, 32)\n",
            "(8736, 257)\n",
            "(1, 32)\n",
            "(8768, 257)\n",
            "(1, 32)\n",
            "(8800, 257)\n",
            "(1, 32)\n",
            "(8832, 257)\n",
            "(1, 32)\n",
            "(8864, 257)\n",
            "(1, 32)\n",
            "(8896, 257)\n",
            "(1, 32)\n",
            "(8928, 257)\n",
            "(1, 32)\n",
            "(8960, 257)\n",
            "(1, 32)\n",
            "(8992, 257)\n",
            "(1, 32)\n",
            "(9024, 257)\n",
            "(1, 32)\n",
            "(9056, 257)\n",
            "(1, 32)\n",
            "(9088, 257)\n",
            "(1, 32)\n",
            "(9120, 257)\n",
            "(1, 32)\n",
            "(9152, 257)\n",
            "(1, 32)\n",
            "(9184, 257)\n",
            "(1, 32)\n",
            "(9216, 257)\n",
            "(1, 32)\n",
            "(9248, 257)\n",
            "(1, 32)\n",
            "(9280, 257)\n",
            "(1, 32)\n",
            "(9312, 257)\n",
            "(1, 27)\n",
            "(9339, 257)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJZidFR_I_VT",
        "outputId": "70b214b2-cb55-4c06-fb25-b42818a0ee98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "latent_z.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9339, 257)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NJxurmYSuiG"
      },
      "source": [
        "save_model_path = 'ResNet-VAE_Exp2_3_1.ResNet-VAE_Encoder_Transfer_Learning'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsvq3MVpEHyc"
      },
      "source": [
        "백업해두자...!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnn_sFXrcKnJ",
        "outputId": "e6080981-93bf-4127-c171-dc4715b9158d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open(('./'+save_model_path+'/{}Epoch_z_vector_eval_2.npy'.format(epoch)), 'wb') as f:\n",
        "        np.save(f, latent_z)  # but latent vector size is (16, 100).... just 16...\n",
        "                                    # 1 Epoch 단위로 latent vector를 저장한다\n",
        "                                    # 이 떄, latent vector의 size는 test_dataset의 크기가 되어야 한다\n",
        "                                    # 결과값이 좋은 vector는 좋은 feature로 사용할 수 있다.\n",
        "# plot latent vector Every 10 Epochs\n",
        "print(\"Svae Latent vector!\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Svae Latent vector!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNvPkfeTimDv"
      },
      "source": [
        "latent_z.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuUr0n1OjhCb"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO39tFdQQTtT"
      },
      "source": [
        "📌 Feature Extraction이후 실험에서는 저장된 numpy값을 불러와서 사용하면 된다 -20.09.29.Tue-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FdyUVcC-tNE",
        "outputId": "3a1545b6-faba-4038-92f0-0c2c0173130f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "source": [
        "! ls"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'01.Tutorial-ResNet-VAE.ipynb의 사본'\n",
            " 01.Tutorial-ResNet-VAE-Recon.ipynb\n",
            " 02.Tutorial-ResNet-VAE-Tunning.ipynb\n",
            " 03.Tutorial-ResNet-VAE-Tunning.ipynb\n",
            "'03.Tutorial-ResNet-VAE-Tunning.ipynb의 사본'\n",
            "'04.Post-01.Tutorial-ResNet-VAE.ipynb사본의 사본'\n",
            "'05.Post-01.Tutorial-ResNet-VAE_Train_Again.ipynb의 사본'\n",
            " 19train_val_plot.png\n",
            " 39train_val_plot.png\n",
            " 59train_val_plot.png\n",
            " Again_ResNet-VAE_Exp01\n",
            "'[Again][ResNet-VAE] Exp2_3_1. Transfer Learning Using ResNet-VAE'\\''Encoer.ipynb'\n",
            "'[Again][ResNet-VAE] Exp2_3_1. Transfer Learning Using ResNet-VAE'\\''Encoer.ipynb의 사본'\n",
            "'[Again][ResNet-VAE] [JICS] Exp01. Feature_Extraction_using pre-trained ResNet-VAE Encoder _and_Classification_Ensemble .ipynb의 사본'\n",
            "'[Again] ResNet-VAE_plus_Classifier .ipynb'\n",
            "'[Again] ResNet-VAE_plus_Classifier .ipynb의 사본'\n",
            "'[Again] Re-Start_Training_ResNet-VAE .ipynb'\n",
            " fig\n",
            " generated_Malimg.png\n",
            " modules.py\n",
            " plot_latent.ipynb\n",
            "'[Post_Exp]04-2.ResNet-VAE_Train_Again.ipynb'\n",
            "'[Post_Exp]04-2.ResNet-VAE_Train_Again.ipynb의 사본'\n",
            "'[Post_Exp]04-3.ResNet-VAE_Train_Again.ipynb'\n",
            "'[Post_Exp]04-3.ResNet-VAE_Train_Again.ipynb의 사본'\n",
            "'[Post_Exp]05-2.ResNet-VAE_Reduce_lr.ipynb'\n",
            " __pycache__\n",
            " README.md\n",
            " reconstruction_Malimg.png\n",
            " ResNetVAE_cifar10.py\n",
            " ResNet-VAE_Exp2_3_1.ResNet-VAE_Encoder_Transfer_Learning\n",
            " ResNet-VAE_Exp2_3_1.ResNet-VAE_Encoder_Transfer_Learning90Epoch_z_vector.npy\n",
            " ResNetVAE_FACE.py\n",
            " ResNetVAE_MNIST.py\n",
            " ResNetVAE_reconstruction.ipynb\n",
            " results_Malimg_Exp4\n",
            " results_Malimg_Exp4_3\n",
            " results_ResNet-VAE_Exp01\n",
            " results_ResNet-VAE_Exp01-Classification_Test\n",
            " save_loss_graph_accuracy.png\n",
            " train_test_loss_plot.png\n",
            " train_val_plot.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjIfsBsr9VIO",
        "outputId": "fc79ac48-4811-4576-8186-17c540521e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('./'+save_model_path+'/90Epoch_z_vector_eval_2.npy')\n",
        "print(epoch)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./ResNet-VAE_Exp2_3_1.ResNet-VAE_Encoder_Transfer_Learning/90Epoch_z_vector_eval_2.npy\n",
            "90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0M0CZRIjBCV",
        "outputId": "23918df6-e90f-44a3-eea2-b4b60fd93aec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "latent_vector = np.load('./'+save_model_path+'/{}Epoch_z_vector_eval_2.npy'.format(epoch))\n",
        "print(\"Load Latent_Vector!!\")\n",
        "latent_vector.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Latent_Vector!!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9339, 257)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAISASxainYg",
        "outputId": "3e2ce9fc-02a1-4c5c-f837-74b28d1054d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"\n",
        "data = latent_vector\n",
        "print(data.shape)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9339, 257)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_W9dDJHinbB",
        "outputId": "6c0ad5fe-e1c0-43fc-8254-0d1d298f64a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "\"\"\"\n",
        "# numpy to pandas\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame(data=data)\n",
        "data.head()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "      <th>231</th>\n",
              "      <th>232</th>\n",
              "      <th>233</th>\n",
              "      <th>234</th>\n",
              "      <th>235</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.079755</td>\n",
              "      <td>-0.147424</td>\n",
              "      <td>-0.189230</td>\n",
              "      <td>0.194458</td>\n",
              "      <td>0.388388</td>\n",
              "      <td>-0.119072</td>\n",
              "      <td>0.109736</td>\n",
              "      <td>-0.056990</td>\n",
              "      <td>-0.800721</td>\n",
              "      <td>0.050581</td>\n",
              "      <td>0.532725</td>\n",
              "      <td>-0.610358</td>\n",
              "      <td>-0.017369</td>\n",
              "      <td>-0.374537</td>\n",
              "      <td>0.208201</td>\n",
              "      <td>-0.799917</td>\n",
              "      <td>-0.427418</td>\n",
              "      <td>-0.318003</td>\n",
              "      <td>-0.198780</td>\n",
              "      <td>-0.363913</td>\n",
              "      <td>0.365756</td>\n",
              "      <td>0.138464</td>\n",
              "      <td>-0.104773</td>\n",
              "      <td>-0.344742</td>\n",
              "      <td>-0.286471</td>\n",
              "      <td>0.257573</td>\n",
              "      <td>0.256363</td>\n",
              "      <td>-0.063435</td>\n",
              "      <td>-0.167919</td>\n",
              "      <td>-0.064486</td>\n",
              "      <td>0.343131</td>\n",
              "      <td>0.126364</td>\n",
              "      <td>0.306907</td>\n",
              "      <td>-0.033746</td>\n",
              "      <td>-0.586487</td>\n",
              "      <td>1.494787</td>\n",
              "      <td>0.050350</td>\n",
              "      <td>-0.292049</td>\n",
              "      <td>0.171634</td>\n",
              "      <td>0.360474</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.507517</td>\n",
              "      <td>0.057923</td>\n",
              "      <td>-0.772096</td>\n",
              "      <td>-0.064201</td>\n",
              "      <td>0.275395</td>\n",
              "      <td>0.477230</td>\n",
              "      <td>0.509851</td>\n",
              "      <td>-0.102962</td>\n",
              "      <td>-0.138262</td>\n",
              "      <td>-0.235437</td>\n",
              "      <td>-0.074715</td>\n",
              "      <td>-0.026238</td>\n",
              "      <td>-0.046062</td>\n",
              "      <td>-0.373379</td>\n",
              "      <td>0.006486</td>\n",
              "      <td>-0.281289</td>\n",
              "      <td>0.081987</td>\n",
              "      <td>-0.494027</td>\n",
              "      <td>-0.317230</td>\n",
              "      <td>0.354119</td>\n",
              "      <td>0.031277</td>\n",
              "      <td>-0.109128</td>\n",
              "      <td>0.068695</td>\n",
              "      <td>0.112275</td>\n",
              "      <td>0.246333</td>\n",
              "      <td>-0.211417</td>\n",
              "      <td>0.058181</td>\n",
              "      <td>-0.148344</td>\n",
              "      <td>-0.095267</td>\n",
              "      <td>0.065737</td>\n",
              "      <td>-0.132259</td>\n",
              "      <td>-0.690135</td>\n",
              "      <td>-0.131619</td>\n",
              "      <td>-0.005944</td>\n",
              "      <td>-0.508376</td>\n",
              "      <td>0.114063</td>\n",
              "      <td>0.047721</td>\n",
              "      <td>0.031916</td>\n",
              "      <td>-0.250866</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.075697</td>\n",
              "      <td>-0.141241</td>\n",
              "      <td>-0.202255</td>\n",
              "      <td>0.196442</td>\n",
              "      <td>0.368280</td>\n",
              "      <td>-0.108913</td>\n",
              "      <td>0.099139</td>\n",
              "      <td>-0.046670</td>\n",
              "      <td>-0.808449</td>\n",
              "      <td>0.057153</td>\n",
              "      <td>0.566733</td>\n",
              "      <td>-0.600700</td>\n",
              "      <td>-0.027950</td>\n",
              "      <td>-0.365823</td>\n",
              "      <td>0.195029</td>\n",
              "      <td>-0.808766</td>\n",
              "      <td>-0.409371</td>\n",
              "      <td>-0.324253</td>\n",
              "      <td>-0.232683</td>\n",
              "      <td>-0.373019</td>\n",
              "      <td>0.370960</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>-0.108057</td>\n",
              "      <td>-0.333581</td>\n",
              "      <td>-0.305560</td>\n",
              "      <td>0.259043</td>\n",
              "      <td>0.227698</td>\n",
              "      <td>-0.055702</td>\n",
              "      <td>-0.177057</td>\n",
              "      <td>-0.072627</td>\n",
              "      <td>0.388489</td>\n",
              "      <td>0.141433</td>\n",
              "      <td>0.334636</td>\n",
              "      <td>-0.029527</td>\n",
              "      <td>-0.607663</td>\n",
              "      <td>1.497099</td>\n",
              "      <td>0.072859</td>\n",
              "      <td>-0.286685</td>\n",
              "      <td>0.197342</td>\n",
              "      <td>0.339403</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.500877</td>\n",
              "      <td>0.042102</td>\n",
              "      <td>-0.776329</td>\n",
              "      <td>-0.034242</td>\n",
              "      <td>0.280909</td>\n",
              "      <td>0.480071</td>\n",
              "      <td>0.531972</td>\n",
              "      <td>-0.126357</td>\n",
              "      <td>-0.140308</td>\n",
              "      <td>-0.253910</td>\n",
              "      <td>-0.033572</td>\n",
              "      <td>-0.028036</td>\n",
              "      <td>-0.052304</td>\n",
              "      <td>-0.364376</td>\n",
              "      <td>-0.007183</td>\n",
              "      <td>-0.286341</td>\n",
              "      <td>0.088019</td>\n",
              "      <td>-0.501302</td>\n",
              "      <td>-0.266955</td>\n",
              "      <td>0.337196</td>\n",
              "      <td>0.037516</td>\n",
              "      <td>-0.117771</td>\n",
              "      <td>0.061113</td>\n",
              "      <td>0.111606</td>\n",
              "      <td>0.229591</td>\n",
              "      <td>-0.199158</td>\n",
              "      <td>0.062549</td>\n",
              "      <td>-0.161465</td>\n",
              "      <td>-0.093055</td>\n",
              "      <td>0.059573</td>\n",
              "      <td>-0.140040</td>\n",
              "      <td>-0.741642</td>\n",
              "      <td>-0.143201</td>\n",
              "      <td>-0.032876</td>\n",
              "      <td>-0.539519</td>\n",
              "      <td>0.110870</td>\n",
              "      <td>0.042003</td>\n",
              "      <td>-0.002187</td>\n",
              "      <td>-0.264128</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.186946</td>\n",
              "      <td>-0.214237</td>\n",
              "      <td>-0.035928</td>\n",
              "      <td>0.453943</td>\n",
              "      <td>0.340568</td>\n",
              "      <td>0.030594</td>\n",
              "      <td>0.291855</td>\n",
              "      <td>-0.119232</td>\n",
              "      <td>-0.593898</td>\n",
              "      <td>0.103341</td>\n",
              "      <td>0.375293</td>\n",
              "      <td>-0.652887</td>\n",
              "      <td>0.254407</td>\n",
              "      <td>-0.426121</td>\n",
              "      <td>0.210909</td>\n",
              "      <td>-0.720233</td>\n",
              "      <td>-0.449404</td>\n",
              "      <td>-0.187847</td>\n",
              "      <td>-0.120922</td>\n",
              "      <td>-0.523257</td>\n",
              "      <td>0.299585</td>\n",
              "      <td>0.173396</td>\n",
              "      <td>0.008157</td>\n",
              "      <td>-0.107134</td>\n",
              "      <td>-0.157367</td>\n",
              "      <td>0.176205</td>\n",
              "      <td>0.302289</td>\n",
              "      <td>-0.023242</td>\n",
              "      <td>-0.074439</td>\n",
              "      <td>0.069249</td>\n",
              "      <td>0.081371</td>\n",
              "      <td>0.067526</td>\n",
              "      <td>0.204558</td>\n",
              "      <td>0.163602</td>\n",
              "      <td>-0.514052</td>\n",
              "      <td>1.542358</td>\n",
              "      <td>0.129169</td>\n",
              "      <td>-0.311420</td>\n",
              "      <td>0.029873</td>\n",
              "      <td>0.121453</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.483379</td>\n",
              "      <td>0.115042</td>\n",
              "      <td>-0.864364</td>\n",
              "      <td>-0.055711</td>\n",
              "      <td>0.385580</td>\n",
              "      <td>0.409733</td>\n",
              "      <td>0.360030</td>\n",
              "      <td>-0.156150</td>\n",
              "      <td>-0.425852</td>\n",
              "      <td>-0.159641</td>\n",
              "      <td>-0.231702</td>\n",
              "      <td>0.111767</td>\n",
              "      <td>-0.102522</td>\n",
              "      <td>-0.358673</td>\n",
              "      <td>0.023472</td>\n",
              "      <td>0.041521</td>\n",
              "      <td>0.043106</td>\n",
              "      <td>-0.481426</td>\n",
              "      <td>-1.051561</td>\n",
              "      <td>0.146567</td>\n",
              "      <td>-0.095436</td>\n",
              "      <td>0.049812</td>\n",
              "      <td>0.129441</td>\n",
              "      <td>-0.058521</td>\n",
              "      <td>0.309234</td>\n",
              "      <td>-0.162010</td>\n",
              "      <td>0.054403</td>\n",
              "      <td>-0.189988</td>\n",
              "      <td>-0.041328</td>\n",
              "      <td>0.271529</td>\n",
              "      <td>-0.227674</td>\n",
              "      <td>-0.943851</td>\n",
              "      <td>0.014254</td>\n",
              "      <td>0.171478</td>\n",
              "      <td>-0.293101</td>\n",
              "      <td>0.091535</td>\n",
              "      <td>0.095283</td>\n",
              "      <td>0.175777</td>\n",
              "      <td>-0.116401</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.183893</td>\n",
              "      <td>-0.218137</td>\n",
              "      <td>-0.033342</td>\n",
              "      <td>0.455784</td>\n",
              "      <td>0.339456</td>\n",
              "      <td>0.032361</td>\n",
              "      <td>0.291033</td>\n",
              "      <td>-0.123609</td>\n",
              "      <td>-0.589514</td>\n",
              "      <td>0.106223</td>\n",
              "      <td>0.367628</td>\n",
              "      <td>-0.653506</td>\n",
              "      <td>0.258564</td>\n",
              "      <td>-0.428709</td>\n",
              "      <td>0.213754</td>\n",
              "      <td>-0.723281</td>\n",
              "      <td>-0.445179</td>\n",
              "      <td>-0.191620</td>\n",
              "      <td>-0.119291</td>\n",
              "      <td>-0.525154</td>\n",
              "      <td>0.299489</td>\n",
              "      <td>0.172470</td>\n",
              "      <td>0.003429</td>\n",
              "      <td>-0.107723</td>\n",
              "      <td>-0.158817</td>\n",
              "      <td>0.173379</td>\n",
              "      <td>0.306515</td>\n",
              "      <td>-0.025969</td>\n",
              "      <td>-0.080091</td>\n",
              "      <td>0.077793</td>\n",
              "      <td>0.076868</td>\n",
              "      <td>0.061462</td>\n",
              "      <td>0.189486</td>\n",
              "      <td>0.166671</td>\n",
              "      <td>-0.507873</td>\n",
              "      <td>1.539625</td>\n",
              "      <td>0.128002</td>\n",
              "      <td>-0.312537</td>\n",
              "      <td>0.029707</td>\n",
              "      <td>0.122561</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.482540</td>\n",
              "      <td>0.121622</td>\n",
              "      <td>-0.860716</td>\n",
              "      <td>-0.056947</td>\n",
              "      <td>0.383539</td>\n",
              "      <td>0.407519</td>\n",
              "      <td>0.356227</td>\n",
              "      <td>-0.148399</td>\n",
              "      <td>-0.427754</td>\n",
              "      <td>-0.154318</td>\n",
              "      <td>-0.239867</td>\n",
              "      <td>0.116229</td>\n",
              "      <td>-0.102825</td>\n",
              "      <td>-0.354691</td>\n",
              "      <td>0.022044</td>\n",
              "      <td>0.043723</td>\n",
              "      <td>0.043092</td>\n",
              "      <td>-0.474519</td>\n",
              "      <td>-1.063762</td>\n",
              "      <td>0.145921</td>\n",
              "      <td>-0.101801</td>\n",
              "      <td>0.047349</td>\n",
              "      <td>0.128657</td>\n",
              "      <td>-0.059488</td>\n",
              "      <td>0.309853</td>\n",
              "      <td>-0.161441</td>\n",
              "      <td>0.047066</td>\n",
              "      <td>-0.189032</td>\n",
              "      <td>-0.034334</td>\n",
              "      <td>0.266426</td>\n",
              "      <td>-0.230699</td>\n",
              "      <td>-0.931323</td>\n",
              "      <td>0.010270</td>\n",
              "      <td>0.168781</td>\n",
              "      <td>-0.286626</td>\n",
              "      <td>0.093486</td>\n",
              "      <td>0.100982</td>\n",
              "      <td>0.186238</td>\n",
              "      <td>-0.115219</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.175223</td>\n",
              "      <td>-0.216755</td>\n",
              "      <td>-0.033997</td>\n",
              "      <td>0.452481</td>\n",
              "      <td>0.324202</td>\n",
              "      <td>0.036710</td>\n",
              "      <td>0.271277</td>\n",
              "      <td>-0.120302</td>\n",
              "      <td>-0.590318</td>\n",
              "      <td>0.109478</td>\n",
              "      <td>0.365225</td>\n",
              "      <td>-0.639969</td>\n",
              "      <td>0.261805</td>\n",
              "      <td>-0.426624</td>\n",
              "      <td>0.216680</td>\n",
              "      <td>-0.721274</td>\n",
              "      <td>-0.413379</td>\n",
              "      <td>-0.188058</td>\n",
              "      <td>-0.137833</td>\n",
              "      <td>-0.527597</td>\n",
              "      <td>0.293229</td>\n",
              "      <td>0.153509</td>\n",
              "      <td>-0.002452</td>\n",
              "      <td>-0.104806</td>\n",
              "      <td>-0.172644</td>\n",
              "      <td>0.172201</td>\n",
              "      <td>0.296448</td>\n",
              "      <td>-0.023418</td>\n",
              "      <td>-0.099792</td>\n",
              "      <td>0.095341</td>\n",
              "      <td>0.103122</td>\n",
              "      <td>0.057123</td>\n",
              "      <td>0.182507</td>\n",
              "      <td>0.163882</td>\n",
              "      <td>-0.517347</td>\n",
              "      <td>1.522830</td>\n",
              "      <td>0.147741</td>\n",
              "      <td>-0.308423</td>\n",
              "      <td>0.043511</td>\n",
              "      <td>0.104968</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.456805</td>\n",
              "      <td>0.129677</td>\n",
              "      <td>-0.905839</td>\n",
              "      <td>-0.046321</td>\n",
              "      <td>0.370809</td>\n",
              "      <td>0.416456</td>\n",
              "      <td>0.367649</td>\n",
              "      <td>-0.152300</td>\n",
              "      <td>-0.429156</td>\n",
              "      <td>-0.160807</td>\n",
              "      <td>-0.228626</td>\n",
              "      <td>0.137353</td>\n",
              "      <td>-0.099813</td>\n",
              "      <td>-0.334947</td>\n",
              "      <td>0.011738</td>\n",
              "      <td>0.044286</td>\n",
              "      <td>0.042627</td>\n",
              "      <td>-0.458977</td>\n",
              "      <td>-1.041680</td>\n",
              "      <td>0.138533</td>\n",
              "      <td>-0.118311</td>\n",
              "      <td>0.036777</td>\n",
              "      <td>0.128950</td>\n",
              "      <td>-0.066132</td>\n",
              "      <td>0.296580</td>\n",
              "      <td>-0.144383</td>\n",
              "      <td>0.035032</td>\n",
              "      <td>-0.188733</td>\n",
              "      <td>-0.005631</td>\n",
              "      <td>0.266176</td>\n",
              "      <td>-0.234222</td>\n",
              "      <td>-0.941512</td>\n",
              "      <td>-0.006849</td>\n",
              "      <td>0.148936</td>\n",
              "      <td>-0.286560</td>\n",
              "      <td>0.102802</td>\n",
              "      <td>0.107672</td>\n",
              "      <td>0.173136</td>\n",
              "      <td>-0.119256</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 257 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3    ...       253       254       255  256\n",
              "0 -0.079755 -0.147424 -0.189230  0.194458  ...  0.047721  0.031916 -0.250866  0.0\n",
              "1 -0.075697 -0.141241 -0.202255  0.196442  ...  0.042003 -0.002187 -0.264128  0.0\n",
              "2 -0.186946 -0.214237 -0.035928  0.453943  ...  0.095283  0.175777 -0.116401  0.0\n",
              "3 -0.183893 -0.218137 -0.033342  0.455784  ...  0.100982  0.186238 -0.115219  0.0\n",
              "4 -0.175223 -0.216755 -0.033997  0.452481  ...  0.107672  0.173136 -0.119256  0.0\n",
              "\n",
              "[5 rows x 257 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hK_pLQ6inet"
      },
      "source": [
        "\"\"\"\n",
        "data.to_csv('./'+save_model_path+ '/ResNet-VAE_Latent_dataset_eval.csv', index=False)\n",
        "df = pd.read_csv('./'+save_model_path+ '/ResNet-VAE_Latent_dataset_eval.csv')\n",
        "df.head()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mewfnzPWk2Kc"
      },
      "source": [
        "## Ensemble Classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhRpAebjR6Uq"
      },
      "source": [
        "### 01. Vanila Voting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erIHB_z5iniZ",
        "outputId": "7269e42a-3a9b-41d7-c2eb-2aa9567c517a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Test-Voting classifier\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# iris = datasets.load_iris()\n",
        "data = latent_vector  # re-change it to numpy\n",
        "X, y = data[:, :256], data[:, 256]\n",
        "\n",
        "clf1 = LogisticRegression(random_state=1)\n",
        "clf2 = RandomForestClassifier(n_estimators=100, random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "\n",
        "eclf = VotingClassifier(\n",
        "         estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
        "         voting='hard')\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
        "     scores = cross_val_score(clf, X, y, scoring='accuracy', cv=10)  # cross validation = 10\n",
        "     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.97 (+/- 0.01) [Logistic Regression]\n",
            "Accuracy: 0.98 (+/- 0.00) [Random Forest]\n",
            "Accuracy: 0.94 (+/- 0.01) [naive Bayes]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.98 (+/- 0.01) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gonOOrQnTr1T"
      },
      "source": [
        "### [Tutorial] Voting Classifier\n",
        "* reference: https://stackabuse.com/ensemble-voting-classification-in-python-with-scikit-learn/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH4B0WaiaJQU",
        "outputId": "ec8de472-5c3c-4c8b-b334-892e61281d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# importing libraries \n",
        "from sklearn.ensemble import VotingClassifier \n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, f1_score, log_loss, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split \n",
        "  \n",
        "# loading iris dataset \n",
        "X, y = data[:, :256], data[:, 256]\n",
        "print(\"Check X, y shape: \", X.shape, y.shape)\n",
        "  \n",
        "# train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(X,  \n",
        "                                                    y,  \n",
        "                                                    test_size = 0.1,  \n",
        "                                                    random_state = 42) \n",
        "  \n",
        "print('train_test_split')\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)  \n",
        "\n",
        "\n",
        "# group / ensemble of models \n",
        "clf1 = LogisticRegression(random_state=1, multi_class ='multinomial')\n",
        "clf2 = RandomForestClassifier(n_estimators=100, random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "\n",
        "vot_hard = VotingClassifier(\n",
        "         estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
        "         voting='soft')\n",
        "\n",
        "# Voting Classifier with hard voting \n",
        "vot_hard.fit(X_train, y_train) \n",
        "y_pred = vot_hard.predict(X_test)\n",
        "  \n",
        "# using accuracy_score metric to predict accuracy\n",
        "\"\"\"\n",
        "score = accuracy_score(y_test, y_pred) \n",
        "print('='*50)\n",
        "print(\"Hard Voting Score % d\" % score) \n",
        "print('='*50)\n",
        "\"\"\"\n",
        "\n",
        "# ===== print unique value y_test, y_pred ===== #\n",
        "print('='*20, 'y_ unique', '='*20)\n",
        "print(np.unique(y_pred), np.unique(y_test))\n",
        "\n",
        "\n",
        "# Reference: https://medium.com/analytics-vidhya/voting-classifier-in-machine-learning-9534504eba39\n",
        "for clf in (clf1, clf2, clf3, vot_hard):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__, 'Accuracy: ', accuracy_score(y_test, y_pred))\n",
        "\n",
        "    print(clf.__class__.__name__, 'Precision: ', precision_score(y_test,y_pred, \n",
        "                                               pos_label='positive',\n",
        "                                               average='micro'))\n",
        "    print(clf.__class__.__name__, 'Recall: ', recall_score(y_test, y_pred, \n",
        "                                          pos_label='positive',\n",
        "                                          average='micro'))\n",
        "    print(clf.__class__.__name__, 'ROC_AUC Score: ', roc_auc_score(y_test, clf.predict_proba(X_test),\n",
        "                                                average='macro',\n",
        "                                                multi_class='ovo'))\n",
        "    \n",
        "    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check X, y shape:  (9339, 256) (9339,)\n",
            "train_test_split\n",
            "(8405, 256) (8405,) (934, 256) (934,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==================== y_ unique ====================\n",
            "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19. 20. 21. 22. 23. 24.] [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19. 20. 21. 22. 23. 24.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression Accuracy:  0.9753747323340471\n",
            "LogisticRegression Precision:  0.9753747323340471\n",
            "LogisticRegression Recall:  0.9753747323340471\n",
            "LogisticRegression ROC_AUC Score:  0.9991517278016196\n",
            "RandomForestClassifier Accuracy:  0.9817987152034261\n",
            "RandomForestClassifier Precision:  0.9817987152034261\n",
            "RandomForestClassifier Recall:  0.9817987152034261\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier ROC_AUC Score:  0.9987855113636362\n",
            "GaussianNB Accuracy:  0.9379014989293362\n",
            "GaussianNB Precision:  0.9379014989293362\n",
            "GaussianNB Recall:  0.9379014989293362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GaussianNB ROC_AUC Score:  0.9955280699069565\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "VotingClassifier Accuracy:  0.9764453961456103\n",
            "VotingClassifier Precision:  0.9764453961456103\n",
            "VotingClassifier Recall:  0.9764453961456103\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "VotingClassifier ROC_AUC Score:  0.9985725791754742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Voting Classifier with soft voting \\neclf =  VotingClassifier(\\n         estimators=[(\\'lr\\', clf1), (\\'rf\\', clf2), (\\'gnb\\', clf3)],\\n         voting=\\'soft\\')\\n\\nfor clf, label in zip([clf1, clf2, clf3, eclf], [\\'Logistic Regression\\', \\'Random Forest\\', \\'naive Bayes\\', \\'Ensemble\\']):\\n     scores = cross_val_score(clf, X_train, y_train, scoring=\\'accuracy\\', cv=10)  # cross validation = 10\\n     print(\"Hard Voting Train Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\\nfor clf, label in zip([clf1, clf2, clf3, eclf], [\\'Logistic Regression\\', \\'Random Forest\\', \\'naive Bayes\\', \\'Ensemble\\']):\\n     scores = cross_val_score(clf, X_test, y_test, scoring=\\'accuracy\\', cv=10)  # cross validation = 10\\n     print(\"Hard Voting Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\\n\\nvot_soft.fit(X_train, y_train) \\ny_pred = vot_soft.predict(X_test) \\n  \\n# using accuracy_score \\nscore = accuracy_score(y_test, y_pred) \\nprint(\"Soft Voting Score % d\" % score)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--Nrb4H4kQy5"
      },
      "source": [
        "* Soft Voting시 Accuracy가 조금 떨어졌다\n",
        "\n",
        "* Evaluation\n",
        "    * VotingClassifier Accuracy:  0.9764453961456103\n",
        "    * VotingClassifier Precision:  0.9764453961456103\n",
        "    * VotingClassifier Recall:  0.9764453961456103\n",
        "    * VotingClassifier ROC_AUC Score:  0. 9985725791754742\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAN3A7sUkomf"
      },
      "source": [
        "같은 hyperparameter에서 'hard voting'으로만 변경해보자<br>\n",
        "단 hard voting은 ROC_AUC Score를 확인할 수 없다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbdxwBVmdPul",
        "outputId": "4640b49e-7d37-4dbd-8e2d-b39aae3789f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "# importing libraries \n",
        "from sklearn.ensemble import VotingClassifier \n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, f1_score, log_loss, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split \n",
        "  \n",
        "# loading iris dataset \n",
        "X, y = data[:, :256], data[:, 256]\n",
        "print(\"Check X, y shape: \", X.shape, y.shape)\n",
        "  \n",
        "# train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(X,  \n",
        "                                                    y,  \n",
        "                                                    test_size = 0.1,  \n",
        "                                                    random_state = 42) \n",
        "  \n",
        "print('train_test_split')\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)  \n",
        "\n",
        "\n",
        "# group / ensemble of models \n",
        "clf1 = LogisticRegression(random_state=1, multi_class ='multinomial')\n",
        "clf2 = RandomForestClassifier(n_estimators=100, random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "\n",
        "vot_hard = VotingClassifier(\n",
        "         estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
        "         voting='hard')  # soft to hard\n",
        "\n",
        "# Voting Classifier with hard voting \n",
        "vot_hard.fit(X_train, y_train) \n",
        "y_pred = vot_hard.predict(X_test)\n",
        "  \n",
        "# using accuracy_score metric to predict accuracy\n",
        "\n",
        "\n",
        "# ===== print unique value y_test, y_pred ===== #\n",
        "print('='*20, 'y_ unique', '='*20)\n",
        "print(np.unique(y_pred), np.unique(y_test))\n",
        "\n",
        "\n",
        "# Reference: https://medium.com/analytics-vidhya/voting-classifier-in-machine-learning-9534504eba39\n",
        "for clf in (clf1, clf2, clf3, vot_hard):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__, 'Accuracy: ', accuracy_score(y_test, y_pred))\n",
        "\n",
        "    print(clf.__class__.__name__, 'Precision: ', precision_score(y_test,y_pred, \n",
        "                                               pos_label='positive',\n",
        "                                               average='micro'))\n",
        "    print(clf.__class__.__name__, 'Recall: ', recall_score(y_test, y_pred, \n",
        "                                          pos_label='positive',\n",
        "                                          average='micro'))\n",
        "    \n",
        "    # print(clf.__class__.__name__, 'ROC_AUC Score: ', roc_auc_score(y_test, clf.predict_proba(X_test),\n",
        "    #                                             average='macro',\n",
        "    #                                             multi_class='ovo'))\n",
        "    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check X, y shape:  (9339, 256) (9339,)\n",
            "train_test_split\n",
            "(8405, 256) (8405,) (934, 256) (934,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==================== y_ unique ====================\n",
            "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19. 20. 21. 22. 23. 24.] [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19. 20. 21. 22. 23. 24.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression Accuracy:  0.9753747323340471\n",
            "LogisticRegression Precision:  0.9753747323340471\n",
            "LogisticRegression Recall:  0.9753747323340471\n",
            "RandomForestClassifier Accuracy:  0.9817987152034261\n",
            "RandomForestClassifier Precision:  0.9817987152034261\n",
            "RandomForestClassifier Recall:  0.9817987152034261\n",
            "GaussianNB Accuracy:  0.9379014989293362\n",
            "GaussianNB Precision:  0.9379014989293362\n",
            "GaussianNB Recall:  0.9379014989293362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "VotingClassifier Accuracy:  0.9817987152034261\n",
            "VotingClassifier Precision:  0.9817987152034261\n",
            "VotingClassifier Recall:  0.9817987152034261\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYFaRHJqlFku"
      },
      "source": [
        "> VotingClassifier Accuracy:  0.9817987152034261<br>\n",
        "> VotingClassifier Precision:  0.9817987152034261<br>\n",
        "> VotingClassifier Recall:  0.9817987152034261"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jPvwyXcrqjh",
        "outputId": "3c97ec23-017d-4c53-fb55-93e9b9f6e9ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# importing libraries \n",
        "from sklearn.ensemble import VotingClassifier \n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.svm import SVC \n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.datasets import load_iris \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.model_selection import train_test_split \n",
        "  \n",
        "# loading iris dataset \n",
        "X = data[:, 0:256]\n",
        "y = data[:, 256]\n",
        "print(\"Check X, y shape: \", X.shape, y.shape)\n",
        "  \n",
        "# train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(X,  \n",
        "                                                    y,  \n",
        "                                                    test_size = 0.20,  \n",
        "                                                    random_state = 42) \n",
        "  \n",
        "print('train_test_split')\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)  \n",
        "# group / ensemble of models \n",
        "\"\"\"\n",
        "estimator = [] \n",
        "estimator.append(('LR',  \n",
        "                  LogisticRegression(solver ='lbfgs',  \n",
        "                                     multi_class ='multinomial',  \n",
        "                                     max_iter = 200))) \n",
        "estimator.append(('SVC', SVC(gamma ='auto', probability = True))) \n",
        "estimator.append(('DTC', DecisionTreeClassifier())) \n",
        "\"\"\"\n",
        "  \n",
        "clf1 = LogisticRegression(random_state=1)\n",
        "clf2 = RandomForestClassifier(n_estimators=100, random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "\n",
        "eclf = VotingClassifier(\n",
        "         estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
        "         voting='hard')\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
        "     scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=10)  # cross validation = 10\n",
        "     print(\"Hard Voting Train Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
        "     scores = cross_val_score(clf, X_test, y_test, scoring='accuracy', cv=10)  # cross validation = 10\n",
        "     print(\"Hard Voting Test Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
        "\"\"\"\n",
        "# Voting Classifier with hard voting \n",
        "vot_hard.fit(X_train, y_train) \n",
        "y_pred = vot_hard.predict(X_test) \n",
        "  \n",
        "# using accuracy_score metric to predict accuracy \n",
        "score = accuracy_score(y_test, y_pred) \n",
        "print(\"Hard Voting Score % d\" % score) \n",
        "\"\"\"\n",
        "# Voting Classifier with soft voting \n",
        "eclf =  VotingClassifier(\n",
        "         estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
        "         voting='soft')\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
        "     scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=10)  # cross validation = 10\n",
        "     print(\"Hard Voting Train Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
        "     scores = cross_val_score(clf, X_test, y_test, scoring='accuracy', cv=10)  # cross validation = 10\n",
        "     print(\"Hard Voting Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
        "\n",
        "\"\"\"\n",
        "vot_soft.fit(X_train, y_train) \n",
        "y_pred = vot_soft.predict(X_test) \n",
        "  \n",
        "# using accuracy_score \n",
        "score = accuracy_score(y_test, y_pred) \n",
        "print(\"Soft Voting Score % d\" % score)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check X, y shape:  (9339, 256) (9339,)\n",
            "train_test_split\n",
            "(7471, 256) (7471,) (1868, 256) (1868,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hard Voting Train Accuracy: 0.97 (+/- 0.00) [Logistic Regression]\n",
            "Hard Voting Train Accuracy: 0.98 (+/- 0.00) [Random Forest]\n",
            "Hard Voting Train Accuracy: 0.94 (+/- 0.00) [naive Bayes]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hard Voting Train Accuracy: 0.98 (+/- 0.00) [Ensemble]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hard Voting Test Accuracy: 0.97 (+/- 0.01) [Logistic Regression]\n",
            "Hard Voting Test Accuracy: 0.98 (+/- 0.01) [Random Forest]\n",
            "Hard Voting Test Accuracy: 0.93 (+/- 0.02) [naive Bayes]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hard Voting Test Accuracy: 0.98 (+/- 0.01) [Ensemble]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hard Voting Train Accuracy: 0.97 (+/- 0.00) [Logistic Regression]\n",
            "Hard Voting Train Accuracy: 0.98 (+/- 0.00) [Random Forest]\n",
            "Hard Voting Train Accuracy: 0.94 (+/- 0.00) [naive Bayes]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hard Voting Train Accuracy: 0.98 (+/- 0.00) [Ensemble]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hard Voting Accuracy: 0.97 (+/- 0.01) [Logistic Regression]\n",
            "Hard Voting Accuracy: 0.98 (+/- 0.01) [Random Forest]\n",
            "Hard Voting Accuracy: 0.93 (+/- 0.02) [naive Bayes]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hard Voting Accuracy: 0.97 (+/- 0.01) [Ensemble]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nvot_soft.fit(X_train, y_train) \\ny_pred = vot_soft.predict(X_test) \\n  \\n# using accuracy_score \\nscore = accuracy_score(y_test, y_pred) \\nprint(\"Soft Voting Score % d\" % score)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uFS5y_4oIVT"
      },
      "source": [
        "### Voting Classifier3\n",
        "* 5 RandomForest\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFT3pQ5Hinpe",
        "outputId": "8ff5b615-8974-4f82-a9d7-a409bdc3ac73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# Test-Voting classifier\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# iris = datasets.load_iris()\n",
        "data = latent_vector  # re-change it to numpy\n",
        "X, y = data[:, :256], data[:, 256]\n",
        "print('='*20,'Shape of X and y', '='*20)\n",
        "print(X.shape, y.shape)\n",
        "print('='*50)\n",
        "\n",
        "\n",
        "clf1 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
        "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
        "clf3 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
        "clf4 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
        "clf5 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
        "\n",
        "eclf = VotingClassifier(\n",
        "         estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
        "         voting='hard')\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, clf4, clf5,  eclf], ['Random Forest', 'Random Forest', 'Random Forest', 'Random Forest', 'Random Forest', 'Ensemble']):\n",
        "     scores = cross_val_score(clf, X, y, scoring='accuracy', cv=10)  # cross validation = 10\n",
        "     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
        "print(\"Done!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================== Shape of X and y ====================\n",
            "(9339, 256) (9339,)\n",
            "==================================================\n",
            "Accuracy: 0.61 (+/- 0.02) [Random Forest]\n",
            "Accuracy: 0.61 (+/- 0.02) [Random Forest]\n",
            "Accuracy: 0.61 (+/- 0.02) [Random Forest]\n",
            "Accuracy: 0.61 (+/- 0.02) [Random Forest]\n",
            "Accuracy: 0.61 (+/- 0.02) [Random Forest]\n",
            "Accuracy: 0.61 (+/- 0.02) [Ensemble]\n",
            "Done!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cJivB-FS0v2"
      },
      "source": [
        "📌 최근에 Refactoring한 코드를 참고해서 본 연구의 실험 코드도 Refactoring 해보자..! <code>-20.09.28.Mon am 01:00</code>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N7aJlnVplo-"
      },
      "source": [
        "### Voting Classifier4\n",
        "* 👨‍🏫 1.11.6.4. Using the VotingClassifier with GridSearchCV\n",
        "   * GridSearch를 통해 최적의 파라미터를 찾아보자\n",
        "   * sklearn Documentation 참고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js3KHAWwq3Ir"
      },
      "source": [
        "Voting Classifier can also be used together with GridSearchCV in order to tune the hyperparameters of the individual estimators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP2rrKPeppv6",
        "outputId": "33c3b2ad-ed5d-49c2-a6b5-714966eef083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# iris = datasets.load_iris()\n",
        "data = latent_vector  # re-change it to numpy\n",
        "X, y = data[:, :256], data[:, 256]\n",
        "print('='*20,'Shape of X and y', '='*20)\n",
        "print(X.shape, y.shape)\n",
        "print('='*50)\n",
        "\n",
        "\n",
        "clf1 = LogisticRegression(random_state=1)\n",
        "clf2 = RandomForestClassifier(random_state=7)\n",
        "clf3 = GaussianNB()\n",
        "eclf = VotingClassifier(\n",
        "    estimators = [('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "params = {'lr__C': [1.0, 100.0], 'rf__n_estimators': [20, 200]}\n",
        "\n",
        "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=10)\n",
        "grid = grid.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================== Shape of X and y ====================\n",
            "(9339, 256) (9339,)\n",
            "==================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMDvIJYLsSbU",
        "outputId": "adccbd39-2393-49a7-e091-51046bddd585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
        "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=10)\n",
        "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.31 (+/- 0.01) [Logistic Regression]\n",
            "Accuracy: 0.62 (+/- 0.03) [Random Forest]\n",
            "Accuracy: 0.44 (+/- 0.01) [naive Bayes]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.50 (+/- 0.01) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAFCiarG3k7I",
        "outputId": "f3e4c618-0afb-447b-a19a-fa42dedb81c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "\n",
        "clf = MLPClassifier(solver='sgd', \n",
        "                    alpha=1e-5,\n",
        "                    # learning_rate=0.001,\n",
        "                    max_iter=200,\n",
        "                    early_stopping=True,\n",
        "                    n_iter_no_change=100,\n",
        "                     hidden_layer_sizes=(15,),\n",
        "                     random_state=1)\n",
        "\n",
        "clf.fit(X, y)\n",
        "\n",
        "\n",
        "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=10)\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9339, 256) (9339,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.48608137 0.49036403 0.52783726 0.51713062 0.51605996 0.51070664\n",
            " 0.51498929 0.53104925 0.5267666  0.53376206]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz1P26qA6mev"
      },
      "source": [
        "## ResNet-VAE Feature Extractor & MLP Classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7ZnVnXJ6wSR"
      },
      "source": [
        "* Process\n",
        "    * pre-trained ResNet-VAE의 Encoder Netwrok로 부터 악성코드의 주요 특징을 추출한 데이터 셋을 구축한다\n",
        "    * Custom Dataset, Custom DataLoader를 다시 구축한다\n",
        "    * MLP 모델을 학습하며 각종 지표들을 검증해본다\n",
        "\n",
        "<br>\n",
        "\n",
        "✅ Re-Factoring Code를 참고하도록 한다...!(from. Stand-DL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdNaENVRUH3p"
      },
      "source": [
        "* From ResNet-VAE & Ensemble - Data Preparation\n",
        "    * <code>latent_vector = np.load('./'+save_model_path+'/{}Epoch_z_vector_eval.npy'.format(epoch))\n",
        "</code>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILVu_7-i3lC7",
        "outputId": "cc9815ac-bdc7-432c-e70a-7198ce0dc89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "latent_vector.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9339, 257)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCs3UKIpVU3k",
        "outputId": "94bdc391-9651-45c1-a790-fc2a8895176c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X = latent_vector[:, :256]\n",
        "y = latent_vector[:, 256]\n",
        "print('print_shape: ', X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "print_shape:  (9339, 256) (9339,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxyNIdWP3k_u"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,  \n",
        "                                                    y,  \n",
        "                                                    test_size = 0.20,  \n",
        "                             å                       random_state = 42) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Gok8wT3k04"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKujaslRybr1"
      },
      "source": [
        "아래의 train code는 ResNet-VAE train Code이다<br>\n",
        "📌📌 => Encoder Network의 Train Code로 변경시켜보자...!<br>\n",
        "* 참고하기\n",
        "    * Reference: https://github.com/Steve-YJ/Assignment_Standalone_DL/blob/master/%5BRe_Fact%5D%20CIFAR-10_CNN_Report_Result.ipynb\n",
        "\n",
        "* Encoder Network에서 <code>mu와 logvar</code>을 잘 활용해보자 -20.09.28.mon-\n",
        "    * ResNet-152 -> FC1 -> FC2 -> mu or logvar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSTYVavF0Af8"
      },
      "source": [
        "## Original Train Code - for ResNet-VAE Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai8Y_drVQGJS"
      },
      "source": [
        "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
        "    # set model as training mode\n",
        "    model.train()\n",
        "\n",
        "    losses = []\n",
        "    all_y, all_z, all_mu, all_logvar = [], [], [], []\n",
        "    N_count = 0   # counting total trained sample in one epoch\n",
        "    for batch_idx, (X, y) in enumerate(train_loader):\n",
        "        # distribute data to device\n",
        "        X, y = X.to(device), y.to(device).view(-1, )\n",
        "        N_count += X.size(0)  # count batch_size sample\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        X_reconst, z, mu, logvar = model(X)  # VAE\n",
        "        loss = loss_function(X_reconst, X, mu, logvar)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        all_y.extend(y.data.cpu().numpy())\n",
        "        all_z.extend(z.data.cpu().numpy())\n",
        "        all_mu.extend(mu.data.cpu().numpy())\n",
        "        all_logvar.extend(logvar.data.cpu().numpy())\n",
        "\n",
        "        # show information\n",
        "        if (batch_idx + 1) % log_interval == 0:  # if batch_size = 16 => 160\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch + 1, N_count, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
        "\n",
        "    # calculate train_loss\n",
        "    losses /= len(train_loader.dataset)\n",
        "    all_y = np.stack(all_y, axis=0)\n",
        "    all_z = np.stack(all_z, axis=0)\n",
        "    all_mu = np.stack(all_mu, axis=0)\n",
        "    all_logvar = np.stack(all_logvar, axis=0)\n",
        "\n",
        "    # save Pytorch models of best record\n",
        "    torch.save(model.state_dict(), os.path.join(save_model_path, 'model_epoch{}.pth'.format(epoch + 1)))  # save motion_encoder\n",
        "    torch.save(optimizer.state_dict(), os.path.join(save_model_path, 'optimizer_epoch{}.pth'.format(epoch + 1)))      # save optimizer\n",
        "    print(\"Epoch {} model saved!\".format(epoch + 1))\n",
        "\n",
        "    return X.data.cpu().numpy(), all_y, all_z, all_mu, all_logvar, losses\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRd5W1pw0F0c"
      },
      "source": [
        "## Train Function for EncoderNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFagIEQ50MrF"
      },
      "source": [
        "* <code>Refactoring</code> Train Function for EncoderNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ECiiksW0I7F"
      },
      "source": [
        "def train(net, trainloader, optimizer, criterion, args):\n",
        "    \n",
        "    \"\"\"\n",
        "    이미 위에서 정의를 해줌\n",
        "    trainloader = torch.utils.data.DataLoader(partition['train'], \n",
        "                                              batch_size=args.train_batch_size, \n",
        "                                              shuffle=True, num_workers=2)\n",
        "    \"\"\"\n",
        "\n",
        "    net.train()  # train mode\n",
        "    optimizer.zero_grad()  # optimizer 초기화\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    train_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # print('input dimension: ', inputs.shape)\n",
        "        # raise RuntimeError\n",
        "        # inputs = inputs.view(-1, 3072)\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = net.encoder(inputs)\n",
        "        \n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = train_loss / len(trainloader)\n",
        "    train_acc = 100 * correct / total\n",
        "    return net, train_loss, train_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDVTUgOH127o"
      },
      "source": [
        "def val(net, valloader, optimizer, criterion, args):\n",
        "    \n",
        "    \"\"\"\n",
        "    이미 위에서 정의를 해줌\n",
        "    valloader = torch.utils.data.DataLoader(partition['train'], \n",
        "                                              batch_size=args.test_batch_size, \n",
        "                                              shuffle=True, num_workers=2)\n",
        "    \"\"\"\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(valloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            # print('input dimension: ', inputs.shape)\n",
        "            # raise RuntimeError\n",
        "            # inputs = inputs.view(-1, 3072)\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(valloader)\n",
        "        val_acc = 100 * correct / total\n",
        "    return val_loss, val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5FQ0cwc22hj"
      },
      "source": [
        "def test(net, testloader, args):\n",
        "    \n",
        "    \"\"\"\n",
        "    이미 위에서 정의를 해줌\n",
        "    testloader = torch.utils.data.DataLoader(partition['train'], \n",
        "                                              batch_size=args.test_batch_size, \n",
        "                                              shuffle=True, num_workers=2)\n",
        "    \"\"\"\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(testloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            # print('input dimension: ', inputs.shape)\n",
        "            # raise RuntimeError\n",
        "            # inputs = inputs.view(-1, 3072)\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "            outputs = net(inputs)\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_acc = 100 * correct / total\n",
        "    return test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2jF7Wpu3ZAb"
      },
      "source": [
        "def experiment(trainloader, valloader, testloader, args):\n",
        "\n",
        "    \"\"\"\n",
        "    net = CNN(model_code = args.model_code,\n",
        "              in_channels = args.in_channels,\n",
        "              out_dim = args.out_dim,\n",
        "              act = args.act,\n",
        "              use_bn = args.use_bn)\n",
        "    net.cuda()\n",
        "    \"\"\"\n",
        "    # Detect devices\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    print(use_cuda)\n",
        "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "    print(device)\n",
        "\n",
        "    \"\"\" \n",
        "    # ====== If you want to use pre-trained model ====== #\n",
        "    \"\"\"\n",
        "    pre_saved_model_path = './results_ResNet-VAE_Exp01'\n",
        "    epoch=90  # pre-trained ResNet-VAE parameter\n",
        "\n",
        "    # Create model\n",
        "    resnet_vae = ResNet_VAE(fc_hidden1=args.CNN_fc_hidden1, fc_hidden2=args.CNN_fc_hidden2, drop_p=args.dropout_p, CNN_embed_dim=args.CNN_embed_dim).to(device)\n",
        "    ### If you want to use pre-trained model ####\n",
        "    resnet_vae.load_state_dict(torch.load(os.path.join(pre_saved_model_path, 'model_epoch{}.pth'.format(epoch))))\n",
        "    \n",
        "    \"\"\"\n",
        "    # resnet_vae에서 encodernet을 어떻게 사용할 수 있을까? -20.09.28.mon-\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "\n",
        "    model_params = list(resnet_vae.parameters())\n",
        "    optimizer = torch.optim.Adam(model_params, lr=args.learning_rate)\n",
        "    ### If you want to use pre-trained model's optimizer ####\n",
        "    optimizer.load_state_dict(torch.load(os.path.join(pre_saved_model_path, 'optimizer_epoch{}.pth'.format(epoch))))\n",
        "\n",
        "\n",
        "    print('Number of {} parameters'.format(sum(p.numel() for p in resnet_vae.parameters() if p.requires_grad)))\n",
        "    print(\"Using\", torch.cuda.device_count(), \"GPU!\")\n",
        "\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if args.optim == 'SGD':\n",
        "        optimizer = optim.SGD(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'RMSprop':\n",
        "        optimizer = optim.RMSprop(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'Adam':\n",
        "        optimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    else:\n",
        "        raise ValueError('In-valid optimizer choice')\n",
        "    \n",
        "    # ===== List for epoch-wise data ====== #\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "    # ================= Training ==================== #\n",
        "        \n",
        "    for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
        "        ts = time.time()\n",
        "        net, train_loss, train_acc = train(net, trainloader, optimizer, criterion, args)\n",
        "        val_loss, val_acc = validate(net, valloader, criterion, args)\n",
        "        te = time.time()\n",
        "        \n",
        "        # ====== Add Epoch Data ====== #\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "        # ============================ #\n",
        "        \n",
        "        print('Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.2f}/{:2.2f}. Took {:2.2f} sec'.format(epoch, train_acc, val_acc, train_loss, val_loss, te-ts))\n",
        "        \n",
        "    test_acc = test(net, testloader, args)    \n",
        "    \n",
        "    # ======= Add Result to Dictionary ======= #\n",
        "    # 전체 결과값을 저장하는 Results Dic \n",
        "    # Q. 왜 때문인진 모르겠지만 train_accs와 train_acc가 분리되어있네?!\n",
        "        # train_acc와 val_acc은 없어도 되는거 아냐?\n",
        "    result = {}\n",
        "    result['train_losses'] = train_losses\n",
        "    result['val_losses'] = val_losses\n",
        "    result['train_accs'] = train_accs\n",
        "    result['val_accs'] = val_accs\n",
        "    # result['train_acc'] = train_acc\n",
        "    # result['val_acc'] = val_acc\n",
        "    result['test_acc'] = test_acc\n",
        "    return vars(args), result  # vars(args)를 해주면 args를 dic로 저장해준다\n",
        "    # ===================================== #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQeEjFenLKb0"
      },
      "source": [
        "# #05. Manage Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO_M_QL2LNos"
      },
      "source": [
        "import hashlib\n",
        "import json\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import pandas as pd\n",
        "\n",
        "def save_exp_result(setting, result):  # setting: args\n",
        "                                       # result : train_losses, val_losses, train_accs, val_accs,  \n",
        "    exp_name = setting['exp_name']\n",
        "    del setting['epoch']               # setting에서 'epoch'과 'test_batch_size'를 제거해준다고...\n",
        "    del setting['test_batch_size']     # 왜 떼는거지?\n",
        "\n",
        "    hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]  # setting에 따라 다른 파일명을 갖도록 만들어준다\n",
        "    filename = './'+save_model_path+'/{}-{}.json'.format(exp_name, hash_key)\n",
        "    # print(filename)\n",
        "    result.update(setting)  # 결과 dictionary에 setting값을 더해준다 => Dic\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(result, f)  # JSON 포멧으로 dictionary 값 저장\n",
        "\n",
        "    \n",
        "def load_exp_result(exp_name):\n",
        "    dir_path = './results'\n",
        "    filenames = [f for f in listdir(dir_path) if isfile(join(dir_path, f)) if '.json' in f]  # ./resuts에 저장되어있는 file들을 리스트 형태로 저장\n",
        "    list_result = []\n",
        "    for filename in filenames:\n",
        "        if exp_name in filename:\n",
        "            # print(exp_name)\n",
        "            with open(join(dir_path, filename), 'r') as infile:\n",
        "                results = json.load(infile)\n",
        "                list_result.append(results)  # Dic을 list형태로 저장\n",
        "    df = pd.DataFrame(list_result) # .drop(columns=[])\n",
        "    return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSqc43qILONJ"
      },
      "source": [
        "# #06. Experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIuSI_v_4jly",
        "outputId": "204de890-9653-48d2-a167-e87e5119e7c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "# ====== Random Seed Initialization ====== #\n",
        "seed = 123  # 랜덤 시드값 초기화\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "args = parser.parse_args(\"\")\n",
        "args.exp_name = \"exp1_lr_model_code\"\n",
        "\n",
        "# ====== Model ====== #\n",
        "# args.model_code ='VGG11'\n",
        "# args.in_channels = 3\n",
        "args.out_dim = 10\n",
        "# args.hid_dim = 100\n",
        "args.act = 'relu'\n",
        "args.CNN_fc_hidden1 = 1024\n",
        "args.CNN_fc_hidden2 = 1024\n",
        "args.CNN_embed_dim = 256  # latent dim extracted by 2D CNN\n",
        "args.res_size = 224       # ResNet Image size\n",
        "args.dropout_p = 0.2           # dropout probability\n",
        "\n",
        "\n",
        "\n",
        "# ====== Regularization ======= #\n",
        "# args.l2 = 0.00001\n",
        "# args.use_bn = True\n",
        "\n",
        "# ====== Optimizer & Training ====== #\n",
        "args.epochs = 20\n",
        "args.learning_rate = 1e-3\n",
        "\n",
        "args.batch_size = 50\n",
        "args.log_interval = 10  # interval for displaying training info\n",
        "\n",
        "print(args)\n",
        "\n",
        "\n",
        "\n",
        "# ===== Experiment Variable ====== #\n",
        "# Reference: https://github.com/Steve-YJ/Assignment_Standalone_DL/blob/master/%5BRe_Fact%5D%20CIFAR-10_CNN_Report_Result.ipynb\n",
        "\n",
        "name_var1 = 'lr'\n",
        "name_var2 = 'hiden_layer_num'\n",
        "list_var1 = [1e-3, 1e-4, 1e-5]\n",
        "list_var2 = [1024, 512, 256, 128, 64, 32]\n",
        "\n",
        "\n",
        "for var1 in list_var1:\n",
        "    for var2 in list_var2:\n",
        "        # setattr ??: name_var1('n_layer')를 1, 2, 3으로 바꿔준다\n",
        "        # setattr = args.name_var1 = var1\n",
        "        setattr(args, name_var1, var1)\n",
        "        setattr(args, name_var2, var2)\n",
        "        print(args)\n",
        "                \n",
        "        setting, result = experiment(train_loader, val_loader, test_loader, args)\n",
        "        save_exp_result(setting, result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(CNN_embed_dim=256, CNN_fc_hidden1=1024, CNN_fc_hidden2=1024, act='relu', batch_size=50, dropout_p=0.2, epochs=20, exp_name='exp1_lr_model_code', learning_rate=0.001, log_interval=10, out_dim=10, res_size=224)\n",
            "Namespace(CNN_embed_dim=256, CNN_fc_hidden1=1024, CNN_fc_hidden2=1024, act='relu', batch_size=50, dropout_p=0.2, epochs=20, exp_name='exp1_lr_model_code', hiden_layer_num=1024, learning_rate=0.001, log_interval=10, lr=0.001, out_dim=10, res_size=224)\n",
            "True\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-bf95261e6ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0msetting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0msave_exp_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-5a88565c6513>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(trainloader, valloader, testloader, args)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mresnet_vae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_saved_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_epoch{}.pth'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# resnet_vae에서 encodernet을 어떻게 사용할 수 있을까?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_vae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_vae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: encode() missing 1 required positional argument: 'x'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T-bIQmv6pFz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeeIDGghLS3J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivli0f62LS84"
      },
      "source": [
        "# #07. Report Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5yifMWjLVtK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}